{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0wvbsXr6C1q",
        "outputId": "39954e29-367a-464c-a804-9122af84b632"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**However, this doesn't install everything quite yet. To select available packages and install different toolkits, use the following cells. This code will open up a GUI which will allow you to run a full installation, or manually select the packages you want.**"
      ],
      "metadata": {
        "id": "j3MzaXIfKA3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbOruUXA7Tqx",
        "outputId": "2d4e9431-24b3-4d51-d186-0ed49f147a9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Examples for Basic Understanding of Natural Language Processing and it's importance and interlink of grammars such as Parts of Speech Tagging (POS Tagging), Adjectives, Adverbs, Nouns and Adverbs. And we will use tokenizaion, stopwords, porterstemmer (like they are basic packages used for NLP)**"
      ],
      "metadata": {
        "id": "5vQZT2mXKN9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "text = \"Myself, Vivek Vardhan (21BAI10029) Pursuing B.Tech at Vellore Institute Of Technology (Bhopal)\"\n",
        "\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt7jffJD6ftJ",
        "outputId": "4f5ea101-01e5-4afb-a86a-16182f957aa7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Myself, Vivek Vardhan (21BAI10029) Pursuing B.Tech at Vellore Institute Of Technology (Bhopal)']\n",
            "['Myself', ',', 'Vivek', 'Vardhan', '(', '21BAI10029', ')', 'Pursuing', 'B.Tech', 'at', 'Vellore', 'Institute', 'Of', 'Technology', '(', 'Bhopal', ')']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkwcEsUY8Mkt",
        "outputId": "0d4959f3-2fed-45f6-ab22-02bcb436adce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "print(set(stopwords.words('english')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW69nO4s7R25",
        "outputId": "9fb23bfe-f8f3-4573-9c84-bb41e294076b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"hadn't\", 'theirs', 'will', \"needn't\", 'can', 's', \"that'll\", 'did', 'between', 'not', 'y', \"isn't\", 'through', 'doesn', \"shan't\", 've', 'by', 'this', 'do', 'both', 'own', 'them', 'or', 'me', 'what', 'herself', 'our', 'after', 'there', \"mightn't\", 'being', 'o', 'won', 'into', \"you'd\", 'as', 'most', 'ma', 'you', 'weren', 'that', 'until', 'here', 'but', 'should', \"shouldn't\", 'had', \"you're\", 'i', \"don't\", 'in', 'other', 'ain', 'below', 'myself', 'how', 'am', 'about', 'before', 'himself', 'we', 'over', 'very', \"aren't\", \"hasn't\", \"wouldn't\", 'when', 'now', 'm', \"won't\", 'hadn', 'where', 'mightn', 'why', 'out', 'isn', \"wasn't\", 'from', 'was', 'each', \"mustn't\", 'for', 'because', 'under', 'yourselves', 'd', 'same', 'didn', 'wouldn', 'couldn', 'yours', \"doesn't\", 'is', 'few', 'shouldn', 'having', 'if', \"it's\", 'wasn', 'yourself', 'a', 'have', 'the', 'at', 'some', 'during', 'these', \"couldn't\", 'such', 're', 'too', 'haven', 'only', \"weren't\", 'who', 'with', 'needn', 'whom', 'its', 'she', 'were', 'all', 'so', 'don', 'again', 'then', 'any', 'against', \"haven't\", 'which', 'mustn', 'itself', 'more', 'their', 'of', 'up', 'are', 'down', 'he', 'him', \"you've\", 'my', 'those', 'an', 'and', 'hasn', 'ourselves', 'no', 'been', 't', \"should've\", 'your', 'll', 'has', \"didn't\", 'shan', 'they', 'further', 'themselves', 'doing', 'off', 'just', \"you'll\", 'than', 'ours', 'it', 'aren', 'does', 'be', 'on', \"she's\", 'to', 'her', 'his', 'nor', 'once', 'above', 'while', 'hers'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sent = \"This is some sample text, showing off the stop words filtration.\"\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "\n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(word_tokens)\n",
        "print(filtered_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDe_hQ7c8ebM",
        "outputId": "79e7750c-db0e-46d7-b795-f9ae2e9f6f57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'some', 'sample', 'text', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
            "['This', 'sample', 'text', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We aim to compare the effectiveness of techniques such as tokenization, stopword removal, stemming, lemmatization, and spell checking in improving the quality of text representations.**\n",
        "\n",
        "Morphological Analysis is a linguistic process that involves analyzing the structure of words to understand their meaning and relationship to other words in a language. In the context of text preprocessing, morphological analysis techniques such as stemming and lemmatization are\n",
        "commonly used to reduce words to their root forms. Stemming involves removing affixes from words to obtain their root forms, while lemmatization maps words to their base or dictionary forms.\n",
        "\n",
        "The effectiveness of preprocessing techniques can vary depending on the language and the specific task at hand. Morphological analysis can improve text preprocessing by capturing the semantic and syntactic variations of words, thus enhancing the quality of text representations."
      ],
      "metadata": {
        "id": "cFybSYte8y8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVedHyZmG_F9",
        "outputId": "54c4a928-ec06-4561-9ffa-764d10602fbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ],
      "metadata": {
        "id": "DTdWkTjtHCk7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PorterStemmer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93pkPCvBGtKp",
        "outputId": "c45a5e09-22b1-41ba-963e-1ea1bea0f8bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PorterStemmer\n",
            "  Downloading PorterStemmer-0.5.tar.gz (5.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: PorterStemmer\n",
            "  Building wheel for PorterStemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PorterStemmer: filename=PorterStemmer-0.5-cp310-cp310-linux_x86_64.whl size=22036 sha256=86ac04e40ad198994672c753a05e14c4f32dfb9b80b2539d74b784daac370fa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/ac/81/2d7badab23de811310a774cb13be403a17fe94e2845105f75e\n",
            "Successfully built PorterStemmer\n",
            "Installing collected packages: PorterStemmer\n",
            "Successfully installed PorterStemmer-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsdGbd8IHLwt",
        "outputId": "b151b749-42e8-47a8-8e43-45a6c175a0b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spellchecker\n",
            "  Downloading spellchecker-0.4.tar.gz (3.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/3.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m3.2/3.9 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spellchecker) (67.7.2)\n",
            "Collecting inexactsearch (from spellchecker)\n",
            "  Downloading inexactsearch-1.0.2.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting soundex>=1.0 (from inexactsearch->spellchecker)\n",
            "  Downloading soundex-1.1.3.tar.gz (9.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting silpa_common>=0.3 (from inexactsearch->spellchecker)\n",
            "  Downloading silpa_common-0.3.tar.gz (9.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: spellchecker, inexactsearch, silpa_common, soundex\n",
            "  Building wheel for spellchecker (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spellchecker: filename=spellchecker-0.4-py3-none-any.whl size=3966500 sha256=439b0f85c67edc6d2b4a25a5468ef025e31c2f062d37f91e3cbbe178905edbcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/90/c3/eac248d8755b2a7343487a2087b4b29ad98f388c3c8c69c286\n",
            "  Building wheel for inexactsearch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inexactsearch: filename=inexactsearch-1.0.2-py3-none-any.whl size=7123 sha256=ae3d83a250152ea5c0c2d71d4ab10d43b056cacaa5391304d4e8681742bf5398\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/19/2c/5e9f447f2533d457a1167c3e553f235e232b8a639e3f5fafab\n",
            "  Building wheel for silpa_common (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for silpa_common: filename=silpa_common-0.3-py3-none-any.whl size=8466 sha256=01a061fd743fad17f9b6079d26ee30fa4041e0e8eaf1d122002a66162b2e952a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/72/43/0c779b79d708c78240beb3b0bb8f5ff3c2ab81c4e5271ea1aa\n",
            "  Building wheel for soundex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for soundex: filename=soundex-1.1.3-py3-none-any.whl size=8876 sha256=a8cbb25b2c0e7440d118b27dd52324c27cd76a52e19c9ff265ee2d4e3bb3ab5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c7/c0/99e0278924f5664ab201bee9eee6e7a856caabf95a6fe008c5\n",
            "Successfully built spellchecker inexactsearch silpa_common soundex\n",
            "Installing collected packages: silpa_common, soundex, inexactsearch, spellchecker\n",
            "Successfully installed inexactsearch-1.0.2 silpa_common-0.3 soundex-1.1.3 spellchecker-0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thU8tWmJHnvL",
        "outputId": "622faf72-2d07-43e4-889d-5fd1d1cd567c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/6.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/6.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "text = \"Over the past two decades, data analysts have gone from being hobbyists about whom coaches were dubious, to playing a core role in picking teams.\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "porter = PorterStemmer()\n",
        "stemmed_words = [porter.stem(word)for word in filtered_tokens]\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize (word) for word in filtered_tokens]\n",
        "\n",
        "spell = SpellChecker()\n",
        "corrected_tokens = [spell.correction (word) for word in filtered_tokens]\n",
        "print(\"Original Tokens:\", tokens)\n",
        "print(\"Filtered Tokens (stopword Removal):\", filtered_tokens)\n",
        "print(\"stemmed Tokens: \", stemmed_words)\n",
        "print(\"lemmatized Tokens: \", lemmatized_words)\n",
        "print(\"Corrected Tokens (Spell Checking):\", corrected_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDGuTSZEHf1t",
        "outputId": "0490f888-137c-480c-94c0-252c15008bb8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens: ['Over', 'the', 'past', 'two', 'decades', ',', 'data', 'analysts', 'have', 'gone', 'from', 'being', 'hobbyists', 'about', 'whom', 'coaches', 'were', 'dubious', ',', 'to', 'playing', 'a', 'core', 'role', 'in', 'picking', 'teams', '.']\n",
            "Filtered Tokens (stopword Removal): ['past', 'two', 'decades', ',', 'data', 'analysts', 'gone', 'hobbyists', 'coaches', 'dubious', ',', 'playing', 'core', 'role', 'picking', 'teams', '.']\n",
            "stemmed Tokens:  ['past', 'two', 'decad', ',', 'data', 'analyst', 'gone', 'hobbyist', 'coach', 'dubiou', ',', 'play', 'core', 'role', 'pick', 'team', '.']\n",
            "lemmatized Tokens:  ['past', 'two', 'decade', ',', 'data', 'analyst', 'gone', 'hobbyist', 'coach', 'dubious', ',', 'playing', 'core', 'role', 'picking', 'team', '.']\n",
            "Corrected Tokens (Spell Checking): ['past', 'two', 'decades', ',', 'data', 'analysts', 'gone', 'hobbyists', 'coaches', 'dubious', ',', 'playing', 'core', 'role', 'picking', 'teams', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluating the performance of N-gram models in text\n",
        "analysis.**\n",
        "\n",
        "N-grams are contiguous sequences of n items (words or characters) in a text. N-gram models are statistical language models that predict the next item in a sequence based on the previous n-1 items.\n",
        "\n",
        "These models are widely used in various text analysis tasks, including language modeling, machine translation, speech recognition, and information retrieval.\n",
        "\n",
        "In N-gram models, the probability of observing a word given its context (previous n-1 words) is estimated from the training data. The choice of the value of n determines the size of the context window and influences the model's ability to capture the dependencies between words.\n",
        "\n",
        "Now we will Generate Unigram (1- gram), Bigram (2- Gram), Trigram (3- gram) just we have taken these 3 grams for simple  understanding as it has N number of frequencies.\n",
        "\n",
        "We will count Frequenices of each n gram and convert frequencies to Dataframe for a better Visualisation and to know the difference between each gram and the counts."
      ],
      "metadata": {
        "id": "D5xuvjQfH6fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install collections\n",
        "\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import collections\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"I first met him briefly before the Indian team left to the 2007 World Cup. Then next I met him straight when he came to CSK. I was at that time in the BCCI. Obviously, after he became captain, I was the treasurer and then secretary - so there were a lot of functions we met.\"\n",
        "\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "unigrams = ngrams (tokens, 1)\n",
        "bigrams = ngrams (tokens, 2)\n",
        "trigrams = ngrams (tokens, 3)\n",
        "\n",
        "unigram_freq = collections.Counter(unigrams)\n",
        "bigram_freq =  collections.Counter(bigrams)\n",
        "trigram_freq = collections.Counter(trigrams)\n",
        "\n",
        "df_unigrams = pd.DataFrame(unigram_freq.items(), columns=['unigram', 'Frequency'])\n",
        "df_bigrams = pd.DataFrame(bigram_freq.items(), columns=['bigram', 'Frequency'])\n",
        "df_trigrams = pd.DataFrame(trigram_freq.items(), columns=['trigram', 'Frequency'])\n",
        "\n",
        "print(\"unigrams: \")\n",
        "print(df_unigrams)\n",
        "print(\"\\nBigrams: \")\n",
        "print(df_bigrams)\n",
        "print(\"\\nTrigrams: \")\n",
        "print(df_trigrams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1YFQ_IRycMQ",
        "outputId": "3c3ab4e6-368d-4ebc-a38a-9ad8020f726f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement collections (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for collections\u001b[0m\u001b[31m\n",
            "\u001b[0munigrams: \n",
            "         unigram  Frequency\n",
            "0           (I,)          4\n",
            "1       (first,)          1\n",
            "2         (met,)          3\n",
            "3         (him,)          2\n",
            "4     (briefly,)          1\n",
            "5      (before,)          1\n",
            "6         (the,)          4\n",
            "7      (Indian,)          1\n",
            "8        (team,)          1\n",
            "9        (left,)          1\n",
            "10         (to,)          2\n",
            "11       (2007,)          1\n",
            "12      (World,)          1\n",
            "13        (Cup,)          1\n",
            "14          (.,)          4\n",
            "15       (Then,)          1\n",
            "16       (next,)          1\n",
            "17   (straight,)          1\n",
            "18       (when,)          1\n",
            "19         (he,)          2\n",
            "20       (came,)          1\n",
            "21        (CSK,)          1\n",
            "22        (was,)          2\n",
            "23         (at,)          1\n",
            "24       (that,)          1\n",
            "25       (time,)          1\n",
            "26         (in,)          1\n",
            "27       (BCCI,)          1\n",
            "28  (Obviously,)          1\n",
            "29          (,,)          2\n",
            "30      (after,)          1\n",
            "31     (became,)          1\n",
            "32    (captain,)          1\n",
            "33  (treasurer,)          1\n",
            "34        (and,)          1\n",
            "35       (then,)          1\n",
            "36  (secretary,)          1\n",
            "37          (-,)          1\n",
            "38         (so,)          1\n",
            "39      (there,)          1\n",
            "40       (were,)          1\n",
            "41          (a,)          1\n",
            "42        (lot,)          1\n",
            "43         (of,)          1\n",
            "44  (functions,)          1\n",
            "45         (we,)          1\n",
            "\n",
            "Bigrams: \n",
            "               bigram  Frequency\n",
            "0          (I, first)          1\n",
            "1        (first, met)          1\n",
            "2          (met, him)          2\n",
            "3      (him, briefly)          1\n",
            "4   (briefly, before)          1\n",
            "5       (before, the)          1\n",
            "6       (the, Indian)          1\n",
            "7      (Indian, team)          1\n",
            "8        (team, left)          1\n",
            "9          (left, to)          1\n",
            "10          (to, the)          1\n",
            "11        (the, 2007)          1\n",
            "12      (2007, World)          1\n",
            "13       (World, Cup)          1\n",
            "14           (Cup, .)          1\n",
            "15          (., Then)          1\n",
            "16       (Then, next)          1\n",
            "17          (next, I)          1\n",
            "18           (I, met)          1\n",
            "19    (him, straight)          1\n",
            "20   (straight, when)          1\n",
            "21         (when, he)          1\n",
            "22         (he, came)          1\n",
            "23         (came, to)          1\n",
            "24          (to, CSK)          1\n",
            "25           (CSK, .)          1\n",
            "26             (., I)          1\n",
            "27           (I, was)          2\n",
            "28          (was, at)          1\n",
            "29         (at, that)          1\n",
            "30       (that, time)          1\n",
            "31         (time, in)          1\n",
            "32          (in, the)          1\n",
            "33        (the, BCCI)          1\n",
            "34          (BCCI, .)          1\n",
            "35     (., Obviously)          1\n",
            "36     (Obviously, ,)          1\n",
            "37         (,, after)          1\n",
            "38        (after, he)          1\n",
            "39       (he, became)          1\n",
            "40  (became, captain)          1\n",
            "41       (captain, ,)          1\n",
            "42             (,, I)          1\n",
            "43         (was, the)          1\n",
            "44   (the, treasurer)          1\n",
            "45   (treasurer, and)          1\n",
            "46        (and, then)          1\n",
            "47  (then, secretary)          1\n",
            "48     (secretary, -)          1\n",
            "49            (-, so)          1\n",
            "50        (so, there)          1\n",
            "51      (there, were)          1\n",
            "52          (were, a)          1\n",
            "53           (a, lot)          1\n",
            "54          (lot, of)          1\n",
            "55    (of, functions)          1\n",
            "56    (functions, we)          1\n",
            "57          (we, met)          1\n",
            "58           (met, .)          1\n",
            "\n",
            "Trigrams: \n",
            "                   trigram  Frequency\n",
            "0          (I, first, met)          1\n",
            "1        (first, met, him)          1\n",
            "2      (met, him, briefly)          1\n",
            "3   (him, briefly, before)          1\n",
            "4   (briefly, before, the)          1\n",
            "5    (before, the, Indian)          1\n",
            "6      (the, Indian, team)          1\n",
            "7     (Indian, team, left)          1\n",
            "8         (team, left, to)          1\n",
            "9          (left, to, the)          1\n",
            "10         (to, the, 2007)          1\n",
            "11      (the, 2007, World)          1\n",
            "12      (2007, World, Cup)          1\n",
            "13         (World, Cup, .)          1\n",
            "14          (Cup, ., Then)          1\n",
            "15         (., Then, next)          1\n",
            "16         (Then, next, I)          1\n",
            "17          (next, I, met)          1\n",
            "18           (I, met, him)          1\n",
            "19    (met, him, straight)          1\n",
            "20   (him, straight, when)          1\n",
            "21    (straight, when, he)          1\n",
            "22        (when, he, came)          1\n",
            "23          (he, came, to)          1\n",
            "24         (came, to, CSK)          1\n",
            "25            (to, CSK, .)          1\n",
            "26             (CSK, ., I)          1\n",
            "27             (., I, was)          1\n",
            "28            (I, was, at)          1\n",
            "29         (was, at, that)          1\n",
            "30        (at, that, time)          1\n",
            "31        (that, time, in)          1\n",
            "32         (time, in, the)          1\n",
            "33         (in, the, BCCI)          1\n",
            "34          (the, BCCI, .)          1\n",
            "35    (BCCI, ., Obviously)          1\n",
            "36       (., Obviously, ,)          1\n",
            "37   (Obviously, ,, after)          1\n",
            "38          (,, after, he)          1\n",
            "39     (after, he, became)          1\n",
            "40   (he, became, captain)          1\n",
            "41    (became, captain, ,)          1\n",
            "42         (captain, ,, I)          1\n",
            "43             (,, I, was)          1\n",
            "44           (I, was, the)          1\n",
            "45   (was, the, treasurer)          1\n",
            "46   (the, treasurer, and)          1\n",
            "47  (treasurer, and, then)          1\n",
            "48  (and, then, secretary)          1\n",
            "49    (then, secretary, -)          1\n",
            "50      (secretary, -, so)          1\n",
            "51          (-, so, there)          1\n",
            "52       (so, there, were)          1\n",
            "53        (there, were, a)          1\n",
            "54          (were, a, lot)          1\n",
            "55            (a, lot, of)          1\n",
            "56    (lot, of, functions)          1\n",
            "57     (of, functions, we)          1\n",
            "58    (functions, we, met)          1\n",
            "59            (we, met, .)          1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part of Speech Tagging with NLTK**\n",
        "\n",
        "Part of speech tagging means labeling words as nouns, verbs, adjectives, etc. Even better, NLTK can handle tenses! While we're at it, we are also going to import a new sentence tokeniz(PunktSentenceTokenizer). This tokenizer is capable of unsupervised learning, so it can be trained on any body of text.\n",
        "\n"
      ],
      "metadata": {
        "id": "EG-65Yaw1sg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGgfGYMJ0XVr",
        "outputId": "b121833f-db09-4476-bbef-e7d317acc6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Error loading 1: Package '1' not found in index\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "Hit Enter to continue: \n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "Hit Enter to continue: \n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "Hit Enter to continue: \n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "Hit Enter to continue: \n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet2022......... Open English Wordnet 2022\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "\n",
            "Collections:\n",
            "  [P] all-corpora......... All the corpora\n",
            "  [P] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "Hit Enter to continue: \n",
            "  [P] all................. All packages\n",
            "  [P] book................ Everything used in the NLTK Book\n",
            "  [P] popular............. Popular packages\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages; [P] marks partially installed collections)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> x\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('udhr')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va-uSeMq4ES5",
        "outputId": "db6b8113-184e-4608-b6f3-69266c5f53f2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/udhr.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import udhr\n",
        "print(udhr.raw('English-Latin1'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ZeFkNU4NtR",
        "outputId": "6a43fc09-d4c7-4c37-9904-b2826df9f50b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Universal Declaration of Human Rights\n",
            "Preamble\n",
            "Whereas recognition of the inherent dignity and of the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world, \n",
            "\n",
            "Whereas disregard and contempt for human rights have resulted in barbarous acts which have outraged the conscience of mankind, and the advent of a world in which human beings shall enjoy freedom of speech and belief and freedom from fear and want has been proclaimed as the highest aspiration of the common people, \n",
            "\n",
            "Whereas it is essential, if man is not to be compelled to have recourse, as a last resort, to rebellion against tyranny and oppression, that human rights should be protected by the rule of law, \n",
            "\n",
            "Whereas it is essential to promote the development of friendly relations between nations, \n",
            "\n",
            "Whereas the peoples of the United Nations have in the Charter reaffirmed their faith in fundamental human rights, in the dignity and worth of the human person and in the equal rights of men and women and have determined to promote social progress and better standards of life in larger freedom, \n",
            "\n",
            "Whereas Member States have pledged themselves to achieve, in cooperation with the United Nations, the promotion of universal respect for and observance of human rights and fundamental freedoms, \n",
            "\n",
            "Whereas a common understanding of these rights and freedoms is of the greatest importance for the full realization of this pledge, \n",
            "\n",
            "Now, therefore, \n",
            "\n",
            "The General Assembly, \n",
            "\n",
            "Proclaims this Universal Declaration of Human Rights as a common standard of achievement for all peoples and all nations, to the end that every individual and every organ of society, keeping this Declaration constantly in mind, shall strive by teaching and education to promote respect for these rights and freedoms and by progressive measures, national and international, to secure their universal and effective recognition and observance, both among the peoples of Member States themselves and among the peoples of territories under their jurisdiction. \n",
            "\n",
            "Article 1 \n",
            "All human beings are born free and equal in dignity and rights. They are endowed with reason and conscience and should act towards one another in a spirit of brotherhood. \n",
            "\n",
            "Article 2 \n",
            "Everyone is entitled to all the rights and freedoms set forth in this Declaration, without distinction of any kind, such as race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status. \n",
            "\n",
            "Furthermore, no distinction shall be made on the basis of the political, jurisdictional or international status of the country or territory to which a person belongs, whether it be independent, trust, non-self-governing or under any other limitation of sovereignty. \n",
            "\n",
            "Article 3 \n",
            "Everyone has the right to life, liberty and security of person. \n",
            "\n",
            "Article 4 \n",
            "No one shall be held in slavery or servitude; slavery and the slave trade shall be prohibited in all their forms. \n",
            "\n",
            "Article 5 \n",
            "No one shall be subjected to torture or to cruel, inhuman or degrading treatment or punishment. \n",
            "\n",
            "Article 6 \n",
            "Everyone has the right to recognition everywhere as a person before the law. \n",
            "\n",
            "Article 7 \n",
            "All are equal before the law and are entitled without any discrimination to equal protection of the law. All are entitled to equal protection against any discrimination in violation of this Declaration and against any incitement to such discrimination. \n",
            "\n",
            "Article 8 \n",
            "Everyone has the right to an effective remedy by the competent national tribunals for acts violating the fundamental rights granted him by the constitution or by law. \n",
            "\n",
            "Article 9 \n",
            "No one shall be subjected to arbitrary arrest, detention or exile. \n",
            "\n",
            "Article 10 \n",
            "Everyone is entitled in full equality to a fair and public hearing by an independent and impartial tribunal, in the determination of his rights and obligations and of any criminal charge against him. \n",
            "\n",
            "Article 11 \n",
            "Everyone charged with a penal offence has the right to be presumed innocent until proved guilty according to law in a public trial at which he has had all the guarantees necessary for his defence. \n",
            "No one shall be held guilty of any penal offence on account of any act or omission which did not constitute a penal offence, under national or international law, at the time when it was committed. Nor shall a heavier penalty be imposed than the one that was applicable at the time the penal offence was committed. \n",
            "Article 12 \n",
            "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honour and reputation. Everyone has the right to the protection of the law against such interference or attacks. \n",
            "\n",
            "Article 13 \n",
            "Everyone has the right to freedom of movement and residence within the borders of each State. \n",
            "Everyone has the right to leave any country, including his own, and to return to his country. \n",
            "Article 14 \n",
            "Everyone has the right to seek and to enjoy in other countries asylum from persecution. \n",
            "This right may not be invoked in the case of prosecutions genuinely arising from non-political crimes or from acts contrary to the purposes and principles of the United Nations. \n",
            "Article 15 \n",
            "Everyone has the right to a nationality. \n",
            "No one shall be arbitrarily deprived of his nationality nor denied the right to change his nationality. \n",
            "Article 16 \n",
            "Men and women of full age, without any limitation due to race, nationality or religion, have the right to marry and to found a family. They are entitled to equal rights as to marriage, during marriage and at its dissolution. \n",
            "Marriage shall be entered into only with the free and full consent of the intending spouses. \n",
            "The family is the natural and fundamental group unit of society and is entitled to protection by society and the State. \n",
            "Article 17 \n",
            "Everyone has the right to own property alone as well as in association with others. \n",
            "No one shall be arbitrarily deprived of his property. \n",
            "Article 18 \n",
            "Everyone has the right to freedom of thought, conscience and religion; this right includes freedom to change his religion or belief, and freedom, either alone or in community with others and in public or private, to manifest his religion or belief in teaching, practice, worship and observance. \n",
            "\n",
            "Article 19 \n",
            "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers. \n",
            "\n",
            "Article 20 \n",
            "Everyone has the right to freedom of peaceful assembly and association. \n",
            "No one may be compelled to belong to an association. \n",
            "Article 21 \n",
            "Everyone has the right to take part in the government of his country, directly or through freely chosen representatives. \n",
            "Everyone has the right to equal access to public service in his country. \n",
            "The will of the people shall be the basis of the authority of government; this will shall be expressed in periodic and genuine elections which shall be by universal and equal suffrage and shall be held by secret vote or by equivalent free voting procedures. \n",
            "Article 22 \n",
            "Everyone, as a member of society, has the right to social security and is entitled to realization, through national effort and international co-operation and in accordance with the organization and resources of each State, of the economic, social and cultural rights indispensable for his dignity and the free development of his personality. \n",
            "\n",
            "Article 23 \n",
            "Everyone has the right to work, to free choice of employment, to just and favourable conditions of work and to protection against unemployment. \n",
            "Everyone, without any discrimination, has the right to equal pay for equal work. \n",
            "Everyone who works has the right to just and favourable remuneration ensuring for himself and his family an existence worthy of human dignity, and supplemented, if necessary, by other means of social protection. \n",
            "Everyone has the right to form and to join trade unions for the protection of his interests. \n",
            "Article 24 \n",
            "Everyone has the right to rest and leisure, including reasonable limitation of working hours and periodic holidays with pay. \n",
            "\n",
            "Article 25 \n",
            "Everyone has the right to a standard of living adequate for the health and well-being of himself and of his family, including food, clothing, housing and medical care and necessary social services, and the right to security in the event of unemployment, sickness, disability, widowhood, old age or other lack of livelihood in circumstances beyond his control. \n",
            "Motherhood and childhood are entitled to special care and assistance. All children, whether born in or out of wedlock, shall enjoy the same social protection. \n",
            "Article 26 \n",
            "Everyone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit. \n",
            "Education shall be directed to the full development of the human personality and to the strengthening of respect for human rights and fundamental freedoms. It shall promote understanding, tolerance and friendship among all nations, racial or religious groups, and shall further the activities of the United Nations for the maintenance of peace. \n",
            "Parents have a prior right to choose the kind of education that shall be given to their children. \n",
            "Article 27 \n",
            "Everyone has the right freely to participate in the cultural life of the community, to enjoy the arts and to share in scientific advancement and its benefits. \n",
            "Everyone has the right to the protection of the moral and material interests resulting from any scientific, literary or artistic production of which he is the author. \n",
            "Article 28 \n",
            "Everyone is entitled to a social and international order in which the rights and freedoms set forth in this Declaration can be fully realized. \n",
            "\n",
            "Article 29 \n",
            "Everyone has duties to the community in which alone th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('state_union')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhWt3be_4ury",
        "outputId": "14e3f006-9ac1-45dd-a342-7c82ac3f9d44"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "\n",
        "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
        "sample_text = state_union.raw(\"2006-GWBush.txt\")"
      ],
      "metadata": {
        "id": "2K4FvUf04r4M"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)"
      ],
      "metadata": {
        "id": "PKS-lX0M46de"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
      ],
      "metadata": {
        "id": "5zdTX4P65ca6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8AS1ddy5xCY",
        "outputId": "c2277eb0-929c-4efc-c344-c094af39c354"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized[:5]:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "            print(tagged)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3OvAHHr5gFZ",
        "outputId": "b59587f8-2184-4561-8bb2-abd9c158f9e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
            "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n",
            "[('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
            "[('(', '('), ('Applause', 'NNP'), ('.', '.'), (')', ')')]\n",
            "[('President', 'NNP'), ('George', 'NNP'), ('W.', 'NNP'), ('Bush', 'NNP'), ('reacts', 'VBZ'), ('to', 'TO'), ('applause', 'VB'), ('during', 'IN'), ('his', 'PRP$'), ('State', 'NNP'), ('of', 'IN'), ('the', 'DT'), ('Union', 'NNP'), ('Address', 'NNP'), ('at', 'IN'), ('the', 'DT'), ('Capitol', 'NNP'), (',', ','), ('Tuesday', 'NNP'), (',', ','), ('Jan', 'NNP'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chunking with NLTK**\n",
        "\n",
        "Now that each word has been tagged with a part of speech, we can move onto chunking: grouping the words into meaningful clusters. The main goal of chunking is to group words into \"noun phrases\", which is a noun with any associated verbs, adjectives, or adverbs.\n",
        "\n",
        "The part of speech tags that were generated in the previous step will be combined with regular expressions, such as the following:\n",
        "\n"
      ],
      "metadata": {
        "id": "O-rQ1pG76HOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "+ = match 1 or more\n",
        "? = match 0 or 1 repetitions.\n",
        "* = match 0 or MORE repetitions\n",
        ". = Any character except a new line\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "boF4dfRw6GMn",
        "outputId": "0b25df7e-3c88-400b-b6b0-41f4576750f1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n+ = match 1 or more\\n? = match 0 or 1 repetitions.\\n* = match 0 or MORE repetitions\\n. = Any character except a new line\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
        "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
        "\n",
        "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
        "\n",
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
        "\n",
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "\n",
        "            # combine the part-of-speech tag with a regular expression\n",
        "\n",
        "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "            chunkParser = nltk.RegexpParser(chunkGram)\n",
        "            chunked = chunkParser.parse(tagged)\n",
        "\n",
        "            # draw the chunks with nltk\n",
        "            # chunked.draw()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "\n",
        "process_content()"
      ],
      "metadata": {
        "id": "1C5MlIZO6Rry"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BfY2M4L26o1p",
        "outputId": "608886d4-2c49-479a-be20-35687709fe9e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nchunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "<RB.?>* = \"0 or more of any tense of adverb,\" followed by:\n",
        "\n",
        "<VB.?>* = \"0 or more of any tense of verb,\" followed by:\n",
        "\n",
        "<NNP>+ = \"One or more proper nouns,\" followed by\n",
        "\n",
        "<NN>? = \"zero or one singular noun.\"\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "22dUoin56uRF",
        "outputId": "e02fa60e-0e67-427c-b9ff-6c5bee8e53b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n<RB.?>* = \"0 or more of any tense of adverb,\" followed by:\\n\\n<VB.?>* = \"0 or more of any tense of verb,\" followed by:\\n\\n<NNP>+ = \"One or more proper nouns,\" followed by\\n\\n<NN>? = \"zero or one singular noun.\"\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "\n",
        "            # combine the part-of-speech tag with a regular expression\n",
        "\n",
        "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "            chunkParser = nltk.RegexpParser(chunkGram)\n",
        "            chunked = chunkParser.parse(tagged)\n",
        "\n",
        "            # print(chunked)\n",
        "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
        "                print(subtree)\n",
        "\n",
        "            # draw the chunks with nltk\n",
        "            # chunked.draw()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IkPyGXF6w97",
        "outputId": "230fa75f-17cc-4f6a-876e-c587d0cac877"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Chunk PRESIDENT/NNP GEORGE/NNP W./NNP BUSH/NNP)\n",
            "(Chunk ADDRESS/NNP)\n",
            "(Chunk A/NNP JOINT/NNP SESSION/NNP)\n",
            "(Chunk THE/NNP CONGRESS/NNP ON/NNP THE/NNP STATE/NNP)\n",
            "(Chunk THE/NNP UNION/NNP January/NNP)\n",
            "(Chunk THE/NNP PRESIDENT/NNP)\n",
            "(Chunk Thank/NNP)\n",
            "(Chunk Mr./NNP Speaker/NNP)\n",
            "(Chunk Vice/NNP President/NNP Cheney/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Supreme/NNP Court/NNP)\n",
            "(Chunk called/VBD America/NNP)\n",
            "(Chunk Coretta/NNP Scott/NNP King/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk State/NNP)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk Capitol/NNP)\n",
            "(Chunk Tuesday/NNP)\n",
            "(Chunk Jan/NNP)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP DraperEvery/NNP time/NN)\n",
            "(Chunk Capitol/NNP dome/NN)\n",
            "(Chunk have/VBP served/VBN America/NNP)\n",
            "(Chunk Tonight/NNP)\n",
            "(Chunk Union/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk September/NNP)\n",
            "(Chunk Dictatorships/NNP shelter/NN)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Afghanistan/NNP)\n",
            "(Chunk Iraqis/NNP)\n",
            "(Chunk Lebanon/NNP)\n",
            "(Chunk Egypt/NNP)\n",
            "(Chunk Syria/NNP)\n",
            "(Chunk Burma/NNP)\n",
            "(Chunk Zimbabwe/NNP)\n",
            "(Chunk North/NNP Korea/NNP)\n",
            "(Chunk Iran/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk Capitol/NNP)\n",
            "(Chunk Tuesday/NNP)\n",
            "(Chunk Jan/NNP)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP No/NNP one/NN)\n",
            "(Chunk Islam/NNP)\n",
            "(Chunk Laden/NNP)\n",
            "(Chunk Middle/NNP East/NNP)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Beslan/NNP)\n",
            "(Chunk London/NNP)\n",
            "(Chunk Earth/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Islam/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Europe/NNP)\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk Capitol/NNP)\n",
            "(Chunk Tuesday/NNP)\n",
            "(Chunk Jan/NNP)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP)\n",
            "(Chunk Afghanistan/NNP)\n",
            "(Chunk President/NNP)\n",
            "(Chunk National/NNP Assembly/NNP)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk 're/VBP helping/VBG Iraqis/NNP)\n",
            "(Chunk Iraqi/NNP government/NN)\n",
            "(Chunk Iraqis/NNP)\n",
            "(Chunk Iraqis/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk Iraqi/NNP security/NN)\n",
            "(Chunk Iraqi/NNP)\n",
            "(Chunk Fellow/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Iraqi/NNP)\n",
            "(Chunk Washington/NNP)\n",
            "(Chunk D.C/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Hindsight/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk Iraqi/NNP)\n",
            "(Chunk Laden/NNP)\n",
            "(Chunk Zarqawi/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Laura/NNP Bush/NNP)\n",
            "(Chunk is/VBZ introduced/VBN Tuesday/NNP evening/NN)\n",
            "(Chunk Jan/NNP)\n",
            "(Chunk State/NNP)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk Capitol/NNP)\n",
            "(Chunk Washington/NNP)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP)\n",
            "(Chunk Staff/NNP Sergeant/NNP Dan/NNP Clay/NNP)\n",
            "(Chunk Fallujah/NNP)\n",
            "(Chunk American/NNP)\n",
            "(Chunk Dan/NNP)\n",
            "(Chunk Staff/NNP Sergeant/NNP Dan/NNP Clay/NNP)\n",
            "(Chunk Lisa/NNP)\n",
            "(Chunk Sara/NNP Jo/NNP)\n",
            "(Chunk Bud/NNP)\n",
            "(Chunk Welcome/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Middle/NNP East/NNP)\n",
            "(Chunk Egypt/NNP)\n",
            "(Chunk Hamas/NNP)\n",
            "(Chunk recognize/VB Israel/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Saudi/NNP Arabia/NNP)\n",
            "(Chunk Middle/NNP East/NNP)\n",
            "(Chunk Middle/NNP East/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk House/NNP Chamber/NNP)\n",
            "(Chunk Union/NNP)\n",
            "(Chunk Tuesday/NNP)\n",
            "(Chunk Jan/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk Capitol/NNP)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP)\n",
            "(Chunk Iran/NNP)\n",
            "(Chunk Lebanon/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Tonight/NNP)\n",
            "(Chunk Iran/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Iran/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Isolationism/NNP)\n",
            "(Chunk God-given/NNP dignity/NN)\n",
            "(Chunk HIV/AIDS/NNP)\n",
            "(Chunk fight/VB AIDS/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Patriot/NNP Act/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk September/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk al/VB Qaeda/NNP)\n",
            "(Chunk Constitution/NNP)\n",
            "(Chunk Qaeda/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Qaeda/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk Roosevelt/NNP)\n",
            "(Chunk Truman/NNP)\n",
            "(Chunk Kennedy/NNP)\n",
            "(Chunk Reagan/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Japan/NNP)\n",
            "(Chunk European/NNP Union/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk China/NNP)\n",
            "(Chunk India/NNP)\n",
            "(Chunk Washington/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Tonight/NNP)\n",
            "(Chunk Keeping/VBG America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk American/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Keeping/VBG America/NNP)\n",
            "(Chunk American/NNP taxpayer/NN)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Dad/NNP)\n",
            "(Chunk President/NNP Clinton/NNP)\n",
            "(Chunk Laughter/NNP)\n",
            "(Chunk Social/NNP Security/NNP)\n",
            "(Chunk Medicare/NNP)\n",
            "(Chunk Medicaid/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk save/VB Social/NNP Security/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Social/NNP Security/NNP)\n",
            "(Chunk Medicare/NNP)\n",
            "(Chunk Medicaid/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Keeping/VBG America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk buy/VB American/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Keeping/VBG America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Keeping/VBG America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk OB/GYN/NNP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Keeping/VBG America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Advanced/NNP Energy/NNP Initiative/NNP)\n",
            "(Chunk Department/NNP)\n",
            "(Chunk Energy/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Middle/NNP East/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Middle/NNP Eastern/NNP oil/NN)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk keep/VB America/NNP)\n",
            "(Chunk Competitiveness/NNP Initiative/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Third/NNP)\n",
            "(Chunk No/NNP Child/NNP Left/NNP Behind/NNP Act/NNP)\n",
            "(Chunk Tonight/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Competitiveness/NNP Initiative/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Government/NNP)\n",
            "(Chunk Wise/NNP)\n",
            "(Chunk Democrat/NNP)\n",
            "(Chunk Republican/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Supreme/NNP Court/NNP)\n",
            "(Chunk Justice/NNP John/NNP Roberts/NNP)\n",
            "(Chunk Justice/NNP Sam/NNP Alito/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Senate/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk American/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk Justice/NNP Sandra/NNP Day/NNP O'Connor/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Tonight/NNP)\n",
            "(Chunk Human/NNP life/NN)\n",
            "(Chunk Creator/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Washington/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Helping/NNP America/NNP)\n",
            "(Chunk Youth/NNP Initiative/NNP)\n",
            "(Chunk First/NNP Lady/NNP)\n",
            "(Chunk Laura/NNP Bush/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Gulf/NNP Coast/NNP)\n",
            "(Chunk New/NNP Orleans/NNP)\n",
            "(Chunk New/NNP Orleans/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk HIV/AIDS/NNP)\n",
            "(Chunk HIV/NNP)\n",
            "(Chunk AIDS/NNP)\n",
            "(Chunk ask/VBP Congress/NNP)\n",
            "(Chunk Ryan/NNP White/NNP Act/NNP)\n",
            "(Chunk AIDS/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk HIV/NNP)\n",
            "(Chunk AIDS/NNP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n",
            "(Chunk Fellow/NNP)\n",
            "(Chunk Lincoln/NNP)\n",
            "(Chunk Martin/NNP Luther/NNP King/NNP)\n",
            "(Chunk Birmingham/NNP)\n",
            "(Chunk Selma/NNP)\n",
            "(Chunk United/NNP)\n",
            "(Chunk Europe/NNP)\n",
            "(Chunk May/NNP God/NNP bless/NN)\n",
            "(Chunk America/NNP)\n",
            "(Chunk Applause/NNP)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chinking with NLTK**\n",
        "\n",
        "Sometimes there are words in the chunks that we don't won't, we can remove them using a process called chinking."
      ],
      "metadata": {
        "id": "9R74pwV17JRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized[5:]:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "\n",
        "            # The main difference here is the }{, vs. the {}. This means we're removing\n",
        "            # from the chink one or more verbs, prepositions, determiners, or the word 'to'.\n",
        "\n",
        "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
        "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
        "\n",
        "            chunkParser = nltk.RegexpParser(chunkGram)\n",
        "            chunked = chunkParser.parse(tagged)\n",
        "\n",
        "            # print(chunked)\n",
        "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
        "                print(subtree)\n",
        "\n",
        "            # chunked.draw()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "\n",
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28AEOISn61Qo",
        "outputId": "d6b6442d-4b8c-4202-b9a7-2c4e832afa66"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Chunk 31/CD ,/, 2006/CD ./.)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP DraperEvery/NNP time/NN I/PRP)\n",
            "(Chunk invited/JJ)\n",
            "(Chunk rostrum/NN ,/, I/PRP)\n",
            "(Chunk privilege/NN ,/, and/CC mindful/NN)\n",
            "(Chunk history/NN we/PRP)\n",
            "(Chunk together/RB ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk Capitol/NNP dome/NN)\n",
            "(Chunk moments/NNS)\n",
            "(Chunk national/JJ mourning/NN and/CC national/JJ achievement/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk one/CD)\n",
            "(Chunk most/RBS consequential/JJ periods/NNS)\n",
            "(Chunk our/PRP$ history/NN --/: and/CC it/PRP)\n",
            "(Chunk my/PRP$ honor/NN)\n",
            "(Chunk you/PRP ./.)\n",
            "(Chunk system/NN)\n",
            "(Chunk\n",
            "  two/CD\n",
            "  parties/NNS\n",
            "  ,/,\n",
            "  two/CD\n",
            "  chambers/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  two/CD\n",
            "  elected/JJ\n",
            "  branches/NNS\n",
            "  ,/,\n",
            "  there/EX\n",
            "  will/MD\n",
            "  always/RB)\n",
            "(Chunk differences/NNS and/CC debate/NN ./.)\n",
            "(Chunk But/CC even/RB tough/JJ debates/NNS can/MD)\n",
            "(Chunk\n",
            "  civil/JJ\n",
            "  tone/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  our/PRP$\n",
            "  differences/NNS\n",
            "  can/MD\n",
            "  not/RB)\n",
            "(Chunk anger/NN ./.)\n",
            "(Chunk great/JJ issues/NNS)\n",
            "(Chunk us/PRP ,/, we/PRP must/MD)\n",
            "(Chunk spirit/NN)\n",
            "(Chunk goodwill/NN and/CC respect/NN)\n",
            "(Chunk one/CD)\n",
            "(Chunk --/: and/CC I/PRP will/MD)\n",
            "(Chunk my/PRP$ part/NN ./.)\n",
            "(Chunk Tonight/NNP)\n",
            "(Chunk state/NN)\n",
            "(Chunk our/PRP$ Union/NNP)\n",
            "(Chunk strong/JJ --/: and/CC together/RB we/PRP will/MD)\n",
            "(Chunk it/PRP stronger/JJR ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk decisive/JJ year/NN ,/, you/PRP and/CC I/PRP will/MD)\n",
            "(Chunk choices/NNS that/WDT)\n",
            "(Chunk future/NN and/CC)\n",
            "(Chunk character/NN)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk confidently/RB)\n",
            "(Chunk enemies/NNS)\n",
            "(Chunk freedom/NN --/: or/CC retreat/NN)\n",
            "(Chunk our/PRP$ duties/NNS)\n",
            "(Chunk hope/NN)\n",
            "(Chunk easier/JJR life/NN ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk our/PRP$ prosperity/NN)\n",
            "(Chunk world/NN economy/NN --/: or/CC)\n",
            "(Chunk ourselves/PRP off/RP)\n",
            "(Chunk trade/NN and/CC opportunity/NN ./.)\n",
            "(Chunk complex/JJ and/CC challenging/JJ time/NN ,/,)\n",
            "(Chunk road/NN)\n",
            "(Chunk isolationism/NN and/CC protectionism/NN may/MD)\n",
            "(Chunk broad/JJ and/CC inviting/NN --/: yet/CC it/PRP)\n",
            "(Chunk danger/NN and/CC decline/NN ./.)\n",
            "(Chunk only/JJ way/NN)\n",
            "(Chunk our/PRP$ people/NNS ,/,)\n",
            "(Chunk only/JJ way/NN)\n",
            "(Chunk peace/NN ,/,)\n",
            "(Chunk only/JJ way/NN)\n",
            "(Chunk our/PRP$ destiny/NN)\n",
            "(Chunk our/PRP$ leadership/NN --/:)\n",
            "(Chunk United/NNP States/NNPS)\n",
            "(Chunk America/NNP will/MD)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Abroad/RB ,/, our/PRP$ nation/NN)\n",
            "(Chunk historic/JJ ,/, long-term/JJ goal/NN --/: we/PRP)\n",
            "(Chunk end/NN)\n",
            "(Chunk tyranny/NN)\n",
            "(Chunk our/PRP$ world/NN ./.)\n",
            "(Chunk goal/NN)\n",
            "(Chunk misguided/JJ idealism/NN ./.)\n",
            "(Chunk reality/NN ,/,)\n",
            "(Chunk future/JJ security/NN)\n",
            "(Chunk America/NNP)\n",
            "(Chunk it/PRP ./.)\n",
            "(Chunk September/NNP)\n",
            "(Chunk 11th/CD ,/, 2001/CD ,/, we/PRP)\n",
            "(Chunk problems/NNS)\n",
            "(Chunk\n",
            "  failed/JJ\n",
            "  and/CC\n",
            "  oppressive/JJ\n",
            "  state/NN\n",
            "  7,000/CD\n",
            "  miles/NNS\n",
            "  away/RB\n",
            "  could/MD)\n",
            "(Chunk murder/NN and/CC destruction/NN)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk Dictatorships/NNP shelter/NN terrorists/NNS ,/, and/CC)\n",
            "(Chunk\n",
            "  resentment/NN\n",
            "  and/CC\n",
            "  radicalism/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  seek/JJ\n",
            "  weapons/NNS)\n",
            "(Chunk mass/NN destruction/NN ./.)\n",
            "(Chunk Democracies/NNS)\n",
            "(Chunk resentment/NN)\n",
            "(Chunk hope/NN ,/,)\n",
            "(Chunk rights/NNS)\n",
            "(Chunk\n",
            "  their/PRP$\n",
            "  citizens/NNS\n",
            "  and/CC\n",
            "  their/PRP$\n",
            "  neighbors/NNS\n",
            "  ,/,\n",
            "  and/CC)\n",
            "(Chunk fight/NN)\n",
            "(Chunk terror/NN ./.)\n",
            "(Chunk step/NN)\n",
            "(Chunk freedom/NN)\n",
            "(Chunk world/NN)\n",
            "(Chunk our/PRP$ country/NN safer/NN --/:)\n",
            "(Chunk we/PRP will/MD)\n",
            "(Chunk boldly/RB)\n",
            "(Chunk freedom/NN 's/POS cause/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Far/RB)\n",
            "(Chunk hopeless/NN dream/NN ,/,)\n",
            "(Chunk advance/NN)\n",
            "(Chunk freedom/NN)\n",
            "(Chunk great/JJ story/NN)\n",
            "(Chunk our/PRP$ time/NN ./.)\n",
            "(Chunk 1945/CD ,/, there/EX)\n",
            "(Chunk about/RB two/CD dozen/NN lonely/RB)\n",
            "(Chunk world/NN ./.)\n",
            "(Chunk Today/NN ,/, there/EX)\n",
            "(Chunk 122/CD ./.)\n",
            "(Chunk And/CC we/PRP)\n",
            "(Chunk new/JJ chapter/NN)\n",
            "(Chunk story/NN)\n",
            "(Chunk self-government/JJ --/:)\n",
            "(Chunk women/NNS)\n",
            "(Chunk up/RP)\n",
            "(Chunk Afghanistan/NNP ,/, and/CC millions/NNS)\n",
            "(Chunk Iraqis/NNP)\n",
            "(Chunk their/PRP$ liberty/NN)\n",
            "(Chunk purple/JJ ink/NN ,/, and/CC men/NNS and/CC women/NNS)\n",
            "(Chunk Lebanon/NNP)\n",
            "(Chunk Egypt/NNP)\n",
            "(Chunk rights/NNS)\n",
            "(Chunk individuals/NNS and/CC)\n",
            "(Chunk necessity/NN)\n",
            "(Chunk freedom/NN ./.)\n",
            "(Chunk start/NN)\n",
            "(Chunk 2006/CD ,/, more/JJR)\n",
            "(Chunk half/PDT)\n",
            "(Chunk people/NNS)\n",
            "(Chunk our/PRP$ world/NN)\n",
            "(Chunk democratic/JJ nations/NNS ./.)\n",
            "(Chunk And/CC we/PRP)\n",
            "(Chunk not/RB)\n",
            "(Chunk other/JJ half/NN --/:)\n",
            "(Chunk places/NNS)\n",
            "(Chunk\n",
            "  Syria/NNP\n",
            "  and/CC\n",
            "  Burma/NNP\n",
            "  ,/,\n",
            "  Zimbabwe/NNP\n",
            "  ,/,\n",
            "  North/NNP\n",
            "  Korea/NNP\n",
            "  ,/,\n",
            "  and/CC\n",
            "  Iran/NNP\n",
            "  --/:)\n",
            "(Chunk demands/NNS)\n",
            "(Chunk justice/NN ,/, and/CC)\n",
            "(Chunk peace/NN)\n",
            "(Chunk world/NN ,/,)\n",
            "(Chunk their/PRP$ freedom/NN ,/, as/RB well/RB ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk his/PRP$ State/NN)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk Capitol/NNP ,/, Tuesday/NNP ,/, Jan/NNP ./.)\n",
            "(Chunk 31/CD ,/, 2006/CD ./.)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP No/NNP one/NN can/MD)\n",
            "(Chunk success/NN)\n",
            "(Chunk freedom/NN ,/, but/CC)\n",
            "(Chunk men/NNS)\n",
            "(Chunk and/CC)\n",
            "(Chunk it/PRP ./.)\n",
            "(Chunk And/CC one/CD)\n",
            "(Chunk main/JJ sources/NNS)\n",
            "(Chunk reaction/NN and/CC opposition/NN)\n",
            "(Chunk radical/JJ Islam/NNP --/:)\n",
            "(Chunk perversion/NN)\n",
            "(Chunk few/JJ)\n",
            "(Chunk noble/JJ faith/NN)\n",
            "(Chunk ideology/NN)\n",
            "(Chunk terror/NN and/CC death/NN ./.)\n",
            "(Chunk Terrorists/NNS)\n",
            "(Chunk bin/NN Laden/NNP)\n",
            "(Chunk serious/JJ)\n",
            "(Chunk mass/NN murder/NN --/: and/CC)\n",
            "(Chunk us/PRP must/MD)\n",
            "(Chunk their/PRP$ declared/JJ intentions/NNS seriously/RB ./.)\n",
            "(Chunk They/PRP)\n",
            "(Chunk heartless/NN system/NN)\n",
            "(Chunk totalitarian/JJ control/NN)\n",
            "(Chunk Middle/NNP East/NNP ,/, and/CC arm/NN themselves/PRP)\n",
            "(Chunk weapons/NNS)\n",
            "(Chunk mass/NN murder/NN ./.)\n",
            "(Chunk Their/PRP$ aim/NN)\n",
            "(Chunk power/NN)\n",
            "(Chunk Iraq/NNP ,/, and/CC)\n",
            "(Chunk it/PRP)\n",
            "(Chunk safe/JJ haven/NN)\n",
            "(Chunk attacks/NNS)\n",
            "(Chunk America/NNP and/CC)\n",
            "(Chunk world/NN ./.)\n",
            "(Chunk military/JJ strength/NN)\n",
            "(Chunk us/PRP directly/RB ,/,)\n",
            "(Chunk terrorists/NNS)\n",
            "(Chunk weapon/NN)\n",
            "(Chunk fear/NN ./.)\n",
            "(Chunk When/WRB they/PRP)\n",
            "(Chunk children/NNS)\n",
            "(Chunk school/NN)\n",
            "(Chunk Beslan/NNP ,/, or/CC)\n",
            "(Chunk up/RP commuters/NNS)\n",
            "(Chunk London/NNP ,/, or/CC)\n",
            "(Chunk bound/NN captive/NN ,/,)\n",
            "(Chunk terrorists/NNS)\n",
            "(Chunk horrors/NNS will/MD)\n",
            "(Chunk our/PRP$ will/MD ,/,)\n",
            "(Chunk violent/NN)\n",
            "(Chunk Earth/NNP ./.)\n",
            "(Chunk But/CC they/PRP)\n",
            "(Chunk :/: We/PRP)\n",
            "(Chunk our/PRP$ freedom/NN ,/, and/CC we/PRP will/MD)\n",
            "(Chunk it/PRP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk time/NN)\n",
            "(Chunk ,/, we/PRP can/MD not/RB)\n",
            "(Chunk security/NN)\n",
            "(Chunk our/PRP$ commitments/NNS and/CC)\n",
            "(Chunk our/PRP$ borders/NNS ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk\n",
            "  vicious/JJ\n",
            "  attackers/NNS\n",
            "  alone/RB\n",
            "  ,/,\n",
            "  they/PRP\n",
            "  would/MD\n",
            "  not/RB)\n",
            "(Chunk us/PRP alone/RB ./.)\n",
            "(Chunk They/PRP would/MD simply/RB)\n",
            "(Chunk battlefield/NN)\n",
            "(Chunk our/PRP$ own/JJ shores/NNS ./.)\n",
            "(Chunk There/EX)\n",
            "(Chunk peace/NN)\n",
            "(Chunk retreat/NN ./.)\n",
            "(Chunk And/CC there/EX)\n",
            "(Chunk honor/NN)\n",
            "(Chunk retreat/NN ./.)\n",
            "(Chunk radical/JJ Islam/NNP)\n",
            "(Chunk its/PRP$ will/MD --/:)\n",
            "(Chunk assaulted/JJ world/NN)\n",
            "(Chunk itself/PRP --/: we/PRP would/MD)\n",
            "(Chunk all/PDT)\n",
            "(Chunk we/PRP)\n",
            "(Chunk longer/RBR)\n",
            "(Chunk our/PRP$ own/JJ ideals/NNS ,/, or/CC even/RB)\n",
            "(Chunk our/PRP$ own/JJ courage/NN ./.)\n",
            "(Chunk\n",
            "  But/CC\n",
            "  our/PRP$\n",
            "  enemies/NNS\n",
            "  and/CC\n",
            "  our/PRP$\n",
            "  friends/NNS\n",
            "  can/MD)\n",
            "(Chunk certain/JJ :/:)\n",
            "(Chunk United/NNP States/NNPS will/MD not/RB)\n",
            "(Chunk world/NN ,/, and/CC we/PRP will/MD never/RB)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP)\n",
            "(Chunk false/JJ comfort/NN)\n",
            "(Chunk isolationism/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk nation/NN)\n",
            "(Chunk liberty/NN)\n",
            "(Chunk Europe/NNP ,/, and/CC)\n",
            "(Chunk death/NN camps/NNS ,/, and/CC)\n",
            "(Chunk up/RP democracies/NNS ,/, and/CC)\n",
            "(Chunk evil/JJ empire/NN ./.)\n",
            "(Chunk Once/RB again/RB ,/, we/PRP)\n",
            "(Chunk call/NN)\n",
            "(Chunk history/NN)\n",
            "(Chunk and/CC)\n",
            "(Chunk world/NN)\n",
            "(Chunk peace/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk offensive/JJ)\n",
            "(Chunk terror/NN networks/NNS ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk or/CC)\n",
            "(Chunk many/JJ)\n",
            "(Chunk their/PRP$ leaders/NNS --/: and/CC)\n",
            "(Chunk others/NNS ,/, their/PRP$ day/NN will/MD)\n",
            "(Chunk ./.)\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk members/NNS)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk his/PRP$ State/NN)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk Capitol/NNP ,/, Tuesday/NNP ,/, Jan/NNP ./.)\n",
            "(Chunk 31/CD ,/, 2006/CD ./.)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP We/PRP)\n",
            "(Chunk offensive/JJ)\n",
            "(Chunk Afghanistan/NNP ,/, where/WRB)\n",
            "(Chunk fine/JJ President/NNP and/CC)\n",
            "(Chunk National/NNP Assembly/NNP)\n",
            "(Chunk terror/NN)\n",
            "(Chunk institutions/NNS)\n",
            "(Chunk new/JJ democracy/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk offensive/JJ)\n",
            "(Chunk Iraq/NNP ,/,)\n",
            "(Chunk clear/JJ plan/NN)\n",
            "(Chunk victory/NN ./.)\n",
            "(Chunk First/RB ,/, we/PRP)\n",
            "(Chunk Iraqis/NNP)\n",
            "(Chunk inclusive/JJ government/NN ,/,)\n",
            "(Chunk old/JJ resentments/NNS will/MD)\n",
            "(Chunk and/CC)\n",
            "(Chunk insurgency/NN will/MD)\n",
            "(Chunk ./.)\n",
            "(Chunk Second/JJ ,/, we/PRP)\n",
            "(Chunk reconstruction/NN efforts/NNS ,/, and/CC)\n",
            "(Chunk Iraqi/NNP government/NN)\n",
            "(Chunk corruption/NN and/CC)\n",
            "(Chunk modern/JJ economy/NN ,/,)\n",
            "(Chunk Iraqis/NNP can/MD)\n",
            "(Chunk benefits/NNS)\n",
            "(Chunk freedom/NN ./.)\n",
            "(Chunk And/CC ,/, third/JJ ,/, we/PRP)\n",
            "(Chunk terrorist/JJ targets/NNS)\n",
            "(Chunk we/PRP)\n",
            "(Chunk Iraqi/JJ forces/NNS that/WDT)\n",
            "(Chunk increasingly/RB capable/JJ)\n",
            "(Chunk enemy/NN ./.)\n",
            "(Chunk Iraqis/NNP)\n",
            "(Chunk their/PRP$ courage/NN)\n",
            "(Chunk day/NN ,/, and/CC we/PRP)\n",
            "(Chunk proud/JJ)\n",
            "(Chunk their/PRP$ allies/NNS)\n",
            "(Chunk cause/NN)\n",
            "(Chunk freedom/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Our/PRP$ work/NN)\n",
            "(Chunk Iraq/NNP)\n",
            "(Chunk difficult/JJ)\n",
            "(Chunk our/PRP$ enemy/NN)\n",
            "(Chunk brutal/JJ ./.)\n",
            "(Chunk But/CC)\n",
            "(Chunk brutality/NN)\n",
            "(Chunk not/RB)\n",
            "(Chunk dramatic/JJ progress/NN)\n",
            "(Chunk new/JJ democracy/NN ./.)\n",
            "(Chunk less/JJR)\n",
            "(Chunk three/CD years/NNS ,/,)\n",
            "(Chunk nation/NN)\n",
            "(Chunk dictatorship/NN)\n",
            "(Chunk liberation/NN ,/,)\n",
            "(Chunk ,/,)\n",
            "(Chunk constitution/NN ,/,)\n",
            "(Chunk national/JJ elections/NNS ./.)\n",
            "(Chunk same/JJ time/NN ,/, our/PRP$ coalition/NN)\n",
            "(Chunk off/RP terrorist/JJ infiltration/NN ,/,)\n",
            "(Chunk out/RP insurgent/JJ strongholds/NNS ,/, and/CC)\n",
            "(Chunk over/RP territory/NN)\n",
            "(Chunk Iraqi/NNP security/NN forces/NNS ./.)\n",
            "(Chunk I/PRP)\n",
            "(Chunk confident/JJ)\n",
            "(Chunk our/PRP$ plan/NN)\n",
            "(Chunk victory/NN ;/: I/PRP)\n",
            "(Chunk confident/JJ)\n",
            "(Chunk will/MD)\n",
            "(Chunk Iraqi/NNP people/NNS ;/: I/PRP)\n",
            "(Chunk confident/JJ)\n",
            "(Chunk skill/NN and/CC spirit/NN)\n",
            "(Chunk our/PRP$ military/JJ ./.)\n",
            "(Chunk Fellow/NNP citizens/NNS ,/, we/PRP)\n",
            "(Chunk fight/NN)\n",
            "(Chunk ,/, and/CC we/PRP)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk road/NN)\n",
            "(Chunk victory/NN)\n",
            "(Chunk road/NN that/WDT will/MD)\n",
            "(Chunk our/PRP$ troops/NNS home/NN ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk progress/NN)\n",
            "(Chunk ground/NN ,/, and/CC Iraqi/NNP forces/NNS increasingly/RB)\n",
            "(Chunk lead/NN ,/, we/PRP should/MD)\n",
            "(Chunk able/JJ)\n",
            "(Chunk further/JJ)\n",
            "(Chunk our/PRP$ troop/NN levels/NNS --/: but/CC)\n",
            "(Chunk decisions/NNS will/MD)\n",
            "(Chunk our/PRP$ military/JJ commanders/NNS ,/, not/RB)\n",
            "(Chunk politicians/NNS)\n",
            "(Chunk Washington/NNP ,/, D.C/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Our/PRP$ coalition/NN)\n",
            "(Chunk our/PRP$ experience/NN)\n",
            "(Chunk Iraq/NNP ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk our/PRP$ military/JJ tactics/NNS and/CC)\n",
            "(Chunk our/PRP$ approach/NN)\n",
            "(Chunk reconstruction/NN ./.)\n",
            "(Chunk way/NN ,/, we/PRP)\n",
            "(Chunk responsible/JJ criticism/NN and/CC counsel/NN)\n",
            "(Chunk members/NNS)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk parties/NNS ./.)\n",
            "(Chunk year/NN ,/, I/PRP will/MD)\n",
            "(Chunk out/RP and/CC)\n",
            "(Chunk your/PRP$ good/JJ advice/NN ./.)\n",
            "(Chunk Yet/RB ,/, there/EX)\n",
            "(Chunk difference/NN)\n",
            "(Chunk responsible/JJ criticism/NN that/WDT)\n",
            "(Chunk success/NN ,/, and/CC defeatism/NN that/WDT)\n",
            "(Chunk anything/NN but/CC failure/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Hindsight/NNP alone/RB)\n",
            "(Chunk not/RB wisdom/JJ ,/, and/CC second-guessing/NN)\n",
            "(Chunk not/RB)\n",
            "(Chunk strategy/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk so/RB much/JJ)\n",
            "(Chunk balance/NN ,/,)\n",
            "(Chunk us/PRP)\n",
            "(Chunk public/JJ office/NN)\n",
            "(Chunk duty/NN)\n",
            "(Chunk candor/NN ./.)\n",
            "(Chunk sudden/JJ withdrawal/NN)\n",
            "(Chunk our/PRP$ forces/NNS)\n",
            "(Chunk Iraq/NNP would/MD)\n",
            "(Chunk our/PRP$ Iraqi/NNP allies/NNS)\n",
            "(Chunk death/NN and/CC prison/NN ,/, would/MD)\n",
            "(Chunk men/NNS)\n",
            "(Chunk bin/NN Laden/NNP and/CC Zarqawi/NNP)\n",
            "(Chunk charge/NN)\n",
            "(Chunk strategic/JJ country/NN ,/, and/CC)\n",
            "(Chunk pledge/NN)\n",
            "(Chunk America/NNP)\n",
            "(Chunk little/JJ ./.)\n",
            "(Chunk Members/NNS)\n",
            "(Chunk Congress/NNP ,/, however/RB we/PRP)\n",
            "(Chunk decisions/NNS and/CC debates/NNS)\n",
            "(Chunk past/NN ,/, our/PRP$ nation/NN)\n",
            "(Chunk only/RB one/CD option/NN :/: We/PRP must/MD)\n",
            "(Chunk our/PRP$ word/NN ,/,)\n",
            "(Chunk our/PRP$ enemies/NNS ,/, and/CC)\n",
            "(Chunk American/JJ military/NN)\n",
            "(Chunk vital/JJ mission/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Laura/NNP Bush/NNP)\n",
            "(Chunk she/PRP)\n",
            "(Chunk Tuesday/NNP evening/NN ,/, Jan/NNP ./.)\n",
            "(Chunk 31/CD ,/, 2006/CD)\n",
            "(Chunk State/NNP)\n",
            "(Chunk Union/NNP Address/NNP)\n",
            "(Chunk United/NNP States/NNPS Capitol/NNP)\n",
            "(Chunk Washington/NNP ./.)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP Our/PRP$ men/NNS and/CC women/NNS)\n",
            "(Chunk uniform/JJ)\n",
            "(Chunk sacrifices/NNS --/: and/CC)\n",
            "(Chunk sense/NN)\n",
            "(Chunk duty/NN stronger/JJR)\n",
            "(Chunk fear/NN ./.)\n",
            "(Chunk They/PRP)\n",
            "(Chunk what/WP it/PRP)\n",
            "(Chunk house/NN)\n",
            "(Chunk house/NN)\n",
            "(Chunk maze/NN)\n",
            "(Chunk streets/NNS ,/,)\n",
            "(Chunk heavy/JJ gear/NN)\n",
            "(Chunk desert/NN heat/NN ,/,)\n",
            "(Chunk comrade/NN)\n",
            "(Chunk roadside/NN bomb/NN ./.)\n",
            "(Chunk And/CC)\n",
            "(Chunk who/WP)\n",
            "(Chunk costs/NNS also/RB)\n",
            "(Chunk stakes/NNS ./.)\n",
            "(Chunk Marine/JJ Staff/NNP Sergeant/NNP Dan/NNP Clay/NNP)\n",
            "(Chunk last/JJ month/NN)\n",
            "(Chunk Fallujah/NNP ./.)\n",
            "(Chunk He/PRP)\n",
            "(Chunk behind/RP)\n",
            "(Chunk letter/NN)\n",
            "(Chunk\n",
            "  his/PRP$\n",
            "  family/NN\n",
            "  ,/,\n",
            "  but/CC\n",
            "  his/PRP$\n",
            "  words/NNS\n",
            "  could/MD\n",
            "  just/RB\n",
            "  as/RB\n",
            "  well/RB)\n",
            "(Chunk American/NNP ./.)\n",
            "(Chunk Here/RB)\n",
            "(Chunk what/WP Dan/NNP)\n",
            "(Chunk :/: ``/`` I/PRP)\n",
            "(Chunk what/WP honor/NN)\n",
            "(Chunk ./.)\n",
            "(Chunk .../: It/PRP)\n",
            "(Chunk honor/NN)\n",
            "(Chunk and/CC)\n",
            "(Chunk you/PRP ./.)\n",
            "(Chunk I/PRP)\n",
            "(Chunk death/NN)\n",
            "(Chunk secure/NN knowledge/NN)\n",
            "(Chunk you/PRP would/MD not/RB)\n",
            "(Chunk Never/RB falter/NN !/.)\n",
            "(Chunk n't/RB)\n",
            "(Chunk and/CC)\n",
            "(Chunk us/PRP who/WP)\n",
            "(Chunk honor/NN)\n",
            "(Chunk which/WDT)\n",
            "(Chunk worth/JJ)\n",
            "(Chunk ./. ''/'')\n",
            "(Chunk\n",
            "  Staff/NNP\n",
            "  Sergeant/NNP\n",
            "  Dan/NNP\n",
            "  Clay/NNP\n",
            "  's/POS\n",
            "  wife/NN\n",
            "  ,/,\n",
            "  Lisa/NNP\n",
            "  ,/,\n",
            "  and/CC\n",
            "  his/PRP$\n",
            "  mom/NN\n",
            "  and/CC\n",
            "  dad/NN\n",
            "  ,/,\n",
            "  Sara/NNP\n",
            "  Jo/NNP\n",
            "  and/CC\n",
            "  Bud/NNP\n",
            "  ,/,)\n",
            "(Chunk us/PRP)\n",
            "(Chunk evening/NN ./.)\n",
            "(Chunk Welcome/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Our/PRP$ nation/NN)\n",
            "(Chunk grateful/JJ)\n",
            "(Chunk ,/, who/WP)\n",
            "(Chunk memory/NN)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk grateful/JJ)\n",
            "(Chunk who/WP)\n",
            "(Chunk our/PRP$ nation/NN 's/POS uniform/NN --/: and/CC)\n",
            "(Chunk we/PRP)\n",
            "(Chunk our/PRP$ brave/NN troops/NNS ,/,)\n",
            "(Chunk us/PRP never/RB)\n",
            "(Chunk sacrifices/NNS)\n",
            "(Chunk America/NNP 's/POS military/JJ families/NNS ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Our/PRP$ offensive/JJ)\n",
            "(Chunk terror/NN)\n",
            "(Chunk more/JJR)\n",
            "(Chunk military/JJ action/NN ./.)\n",
            "(Chunk Ultimately/RB ,/,)\n",
            "(Chunk only/JJ way/NN)\n",
            "(Chunk terrorists/NNS)\n",
            "(Chunk their/PRP$ dark/JJ vision/NN)\n",
            "(Chunk and/CC)\n",
            "(Chunk hopeful/JJ alternative/NN)\n",
            "(Chunk political/JJ freedom/NN and/CC peaceful/JJ change/NN ./.)\n",
            "(Chunk United/NNP States/NNPS)\n",
            "(Chunk America/NNP supports/NNS democratic/JJ reform/NN)\n",
            "(Chunk broader/JJR Middle/NNP East/NNP ./.)\n",
            "(Chunk Elections/NNS)\n",
            "(Chunk vital/JJ ,/, but/CC they/PRP)\n",
            "(Chunk only/RB)\n",
            "(Chunk beginning/NN ./.)\n",
            "(Chunk up/RP)\n",
            "(Chunk democracy/NN)\n",
            "(Chunk rule/NN)\n",
            "(Chunk law/NN ,/, and/CC protection/NN)\n",
            "(Chunk\n",
            "  minorities/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  strong/JJ\n",
            "  ,/,\n",
            "  accountable/JJ\n",
            "  institutions/NNS)\n",
            "(Chunk last/JJ longer/JJR)\n",
            "(Chunk single/JJ vote/NN ./.)\n",
            "(Chunk great/JJ people/NNS)\n",
            "(Chunk Egypt/NNP)\n",
            "(Chunk\n",
            "  multi-party/JJ\n",
            "  presidential/JJ\n",
            "  election/NN\n",
            "  --/:\n",
            "  and/CC\n",
            "  now/RB\n",
            "  their/PRP$\n",
            "  government/NN\n",
            "  should/MD)\n",
            "(Chunk paths/NNS)\n",
            "(Chunk peaceful/JJ opposition/NN that/WDT will/MD)\n",
            "(Chunk appeal/NN)\n",
            "(Chunk radicalism/NN ./.)\n",
            "(Chunk Palestinian/JJ people/NNS)\n",
            "(Chunk elections/NNS ./.)\n",
            "(Chunk And/CC now/RB)\n",
            "(Chunk leaders/NNS)\n",
            "(Chunk Hamas/NNP must/MD)\n",
            "(Chunk\n",
            "  Israel/NNP\n",
            "  ,/,\n",
            "  disarm/NN\n",
            "  ,/,\n",
            "  reject/JJ\n",
            "  terrorism/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  work/NN)\n",
            "(Chunk peace/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Saudi/NNP Arabia/NNP)\n",
            "(Chunk first/JJ steps/NNS)\n",
            "(Chunk reform/NN --/: now/RB it/PRP can/MD)\n",
            "(Chunk its/PRP$ people/NNS)\n",
            "(Chunk better/JJR future/NN)\n",
            "(Chunk forward/RB)\n",
            "(Chunk efforts/NNS ./.)\n",
            "(Chunk Democracies/NNS)\n",
            "(Chunk Middle/NNP East/NNP will/MD not/RB)\n",
            "(Chunk our/PRP$ own/JJ ,/,)\n",
            "(Chunk they/PRP will/MD)\n",
            "(Chunk traditions/NNS)\n",
            "(Chunk their/PRP$ own/JJ citizens/NNS ./.)\n",
            "(Chunk Yet/RB liberty/NN)\n",
            "(Chunk future/NN)\n",
            "(Chunk nation/NN)\n",
            "(Chunk Middle/NNP East/NNP ,/,)\n",
            "(Chunk liberty/NN)\n",
            "(Chunk right/NN and/CC hope/NN)\n",
            "(Chunk humanity/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk President/NNP George/NNP W./NNP Bush/NNP)\n",
            "(Chunk upper/JJ visitors/NNS gallery/NN)\n",
            "(Chunk House/NNP Chamber/NNP)\n",
            "(Chunk his/PRP$ State/NN)\n",
            "(Chunk Union/NNP remarks/NNS Tuesday/NNP ,/, Jan/NNP ./.)\n",
            "(Chunk 31/CD ,/, 2006/CD)\n",
            "(Chunk United/NNP States/NNPS Capitol/NNP ./.)\n",
            "(Chunk White/NNP House/NNP photo/NN)\n",
            "(Chunk Eric/NNP Draper/NNP)\n",
            "(Chunk same/JJ)\n",
            "(Chunk true/JJ)\n",
            "(Chunk Iran/NNP ,/,)\n",
            "(Chunk nation/NN now/RB)\n",
            "(Chunk hostage/NN)\n",
            "(Chunk small/JJ clerical/JJ elite/NN that/WDT)\n",
            "(Chunk and/CC)\n",
            "(Chunk its/PRP$ people/NNS ./.)\n",
            "(Chunk regime/NN)\n",
            "(Chunk country/NN sponsors/NNS terrorists/NNS)\n",
            "(Chunk Palestinian/JJ territories/NNS and/CC)\n",
            "(Chunk Lebanon/NNP --/: and/CC)\n",
            "(Chunk must/MD)\n",
            "(Chunk end/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Iranian/JJ government/NN)\n",
            "(Chunk world/NN)\n",
            "(Chunk its/PRP$ nuclear/JJ ambitions/NNS ,/, and/CC)\n",
            "(Chunk nations/NNS)\n",
            "(Chunk world/NN must/MD not/RB)\n",
            "(Chunk Iranian/JJ regime/NN)\n",
            "(Chunk nuclear/JJ weapons/NNS ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP will/MD)\n",
            "(Chunk world/NN)\n",
            "(Chunk threats/NNS ./.)\n",
            "(Chunk Tonight/NNP ,/,)\n",
            "(Chunk me/PRP)\n",
            "(Chunk directly/RB)\n",
            "(Chunk citizens/NNS)\n",
            "(Chunk Iran/NNP :/: America/NNP)\n",
            "(Chunk you/PRP ,/, and/CC we/PRP)\n",
            "(Chunk your/PRP$ country/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk your/PRP$ right/NN)\n",
            "(Chunk your/PRP$ own/JJ future/NN and/CC)\n",
            "(Chunk your/PRP$ own/JJ freedom/NN ./.)\n",
            "(Chunk And/CC our/PRP$ nation/NN)\n",
            "(Chunk one/CD day/NN)\n",
            "(Chunk closest/JJS)\n",
            "(Chunk friends/NNS)\n",
            "(Chunk free/JJ and/CC democratic/JJ Iran/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk dangers/NNS)\n",
            "(Chunk our/PRP$ world/NN ,/, we/PRP must/MD also/RB)\n",
            "(Chunk offensive/JJ)\n",
            "(Chunk economic/JJ progress/NN ,/, and/CC)\n",
            "(Chunk disease/NN ,/, and/CC)\n",
            "(Chunk hope/NN)\n",
            "(Chunk hopeless/JJ lands/NNS ./.)\n",
            "(Chunk Isolationism/NNP would/MD not/RB only/RB)\n",
            "(Chunk our/PRP$ hands/NNS)\n",
            "(Chunk enemies/NNS ,/, it/PRP would/MD)\n",
            "(Chunk us/PRP)\n",
            "(Chunk our/PRP$ friends/NNS)\n",
            "(Chunk desperate/JJ need/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk compassion/JJ abroad/RB)\n",
            "(Chunk Americans/NNPS)\n",
            "(Chunk God-given/NNP dignity/NN and/CC worth/NN)\n",
            "(Chunk villager/NN)\n",
            "(Chunk HIV/AIDS/NNP ,/, or/CC)\n",
            "(Chunk infant/NN)\n",
            "(Chunk malaria/NNS ,/, or/CC)\n",
            "(Chunk refugee/JJ fleeing/NN genocide/NN ,/, or/CC)\n",
            "(Chunk young/JJ girl/NN)\n",
            "(Chunk slavery/NN ./.)\n",
            "(Chunk We/PRP also/RB)\n",
            "(Chunk compassion/NN abroad/RB)\n",
            "(Chunk regions/NNS)\n",
            "(Chunk poverty/NN ,/, corruption/NN ,/, and/CC despair/NN)\n",
            "(Chunk sources/NNS)\n",
            "(Chunk terrorism/NN ,/, and/CC)\n",
            "(Chunk crime/NN ,/, and/CC human/JJ trafficking/NN ,/, and/CC)\n",
            "(Chunk drug/NN trade/NN ./.)\n",
            "(Chunk recent/JJ years/NNS ,/, you/PRP and/CC I/PRP)\n",
            "(Chunk unprecedented/JJ action/NN)\n",
            "(Chunk AIDS/NNP and/CC malaria/NNS ,/,)\n",
            "(Chunk education/NN)\n",
            "(Chunk girls/NNS ,/, and/CC reward/RB)\n",
            "(Chunk nations/NNS that/WDT)\n",
            "(Chunk forward/RB)\n",
            "(Chunk economic/JJ and/CC political/JJ reform/NN ./.)\n",
            "(Chunk people/NNS everywhere/RB ,/,)\n",
            "(Chunk United/NNP States/NNPS)\n",
            "(Chunk partner/NN)\n",
            "(Chunk better/JJR life/NN ./.)\n",
            "(Chunk efforts/NNS would/MD)\n",
            "(Chunk suffering/NN and/CC chaos/NN)\n",
            "(Chunk\n",
            "  our/PRP$\n",
            "  world/NN\n",
            "  ,/,\n",
            "  undercut/JJ\n",
            "  our/PRP$\n",
            "  long-term/JJ\n",
            "  security/NN\n",
            "  ,/,\n",
            "  and/CC)\n",
            "(Chunk conscience/NN)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk I/PRP)\n",
            "(Chunk members/NNS)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk interests/NNS)\n",
            "(Chunk America/NNP)\n",
            "(Chunk compassion/NN)\n",
            "(Chunk America/NNP ./.)\n",
            "(Chunk Our/PRP$ country/NN must/MD also/RB)\n",
            "(Chunk offensive/JJ)\n",
            "(Chunk terrorism/NN here/RB)\n",
            "(Chunk home/NN ./.)\n",
            "(Chunk enemy/NN)\n",
            "(Chunk not/RB)\n",
            "(Chunk desire/NN or/CC capability/NN)\n",
            "(Chunk us/PRP ./.)\n",
            "(Chunk Fortunately/RB ,/,)\n",
            "(Chunk nation/NN)\n",
            "(Chunk professionals/NNS)\n",
            "(Chunk law/NN enforcement/NN ,/, intelligence/NN ,/,)\n",
            "(Chunk military/JJ ,/, and/CC)\n",
            "(Chunk security/NN ./.)\n",
            "(Chunk men/NNS and/CC women/NNS)\n",
            "(Chunk their/PRP$ lives/NNS ,/,)\n",
            "(Chunk us/PRP)\n",
            "(Chunk ,/, and/CC they/PRP)\n",
            "(Chunk our/PRP$ support/NN and/CC our/PRP$ thanks/NNS ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk They/PRP also/RB)\n",
            "(Chunk same/JJ tools/NNS they/PRP already/RB)\n",
            "(Chunk drug/NN trafficking/NN and/CC)\n",
            "(Chunk crime/NN --/: so/RB I/PRP)\n",
            "(Chunk you/PRP)\n",
            "(Chunk Patriot/NNP Act/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk It/PRP)\n",
            "(Chunk prior/JJ)\n",
            "(Chunk attacks/NNS)\n",
            "(Chunk September/NNP)\n",
            "(Chunk 11th/CD ,/, our/PRP$ government/NN)\n",
            "(Chunk dots/NNS)\n",
            "(Chunk conspiracy/NN ./.)\n",
            "(Chunk We/PRP now/RB)\n",
            "(Chunk two/CD)\n",
            "(Chunk hijackers/NNS)\n",
            "(Chunk United/NNP States/NNPS)\n",
            "(Chunk telephone/NN calls/NNS)\n",
            "(Chunk Qaeda/NNP)\n",
            "(Chunk overseas/RB ./.)\n",
            "(Chunk But/CC we/PRP)\n",
            "(Chunk not/RB)\n",
            "(Chunk their/PRP$ plans/NNS)\n",
            "(Chunk it/PRP)\n",
            "(Chunk too/RB late/JJ ./.)\n",
            "(Chunk So/RB)\n",
            "(Chunk attack/NN --/:)\n",
            "(Chunk authority/NN)\n",
            "(Chunk me/PRP)\n",
            "(Chunk Constitution/NNP and/CC)\n",
            "(Chunk statute/NN --/: I/PRP)\n",
            "(Chunk terrorist/JJ surveillance/NN program/NN)\n",
            "(Chunk aggressively/RB)\n",
            "(Chunk international/JJ communications/NNS)\n",
            "(Chunk\n",
            "  suspected/JJ\n",
            "  al/JJ\n",
            "  Qaeda/NNP\n",
            "  operatives/NNS\n",
            "  and/CC\n",
            "  affiliates/NNS)\n",
            "(Chunk and/CC)\n",
            "(Chunk America/NNP ./.)\n",
            "(Chunk Previous/JJ Presidents/NNS)\n",
            "(Chunk same/JJ constitutional/JJ authority/NN I/PRP)\n",
            "(Chunk ,/, and/CC federal/JJ courts/NNS)\n",
            "(Chunk use/NN)\n",
            "(Chunk authority/NN ./.)\n",
            "(Chunk Appropriate/JJ members/NNS)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk ./.)\n",
            "(Chunk terrorist/JJ surveillance/NN program/NN)\n",
            "(Chunk terrorist/JJ attacks/NNS ./.)\n",
            "(Chunk It/PRP)\n",
            "(Chunk essential/JJ)\n",
            "(Chunk security/NN)\n",
            "(Chunk America/NNP ./.)\n",
            "(Chunk there/EX)\n",
            "(Chunk people/NNS)\n",
            "(Chunk our/PRP$ country/NN who/WP)\n",
            "(Chunk al/NN Qaeda/NNP ,/, we/PRP)\n",
            "(Chunk it/PRP ,/,)\n",
            "(Chunk we/PRP will/MD not/RB)\n",
            "(Chunk back/RB and/CC wait/NN)\n",
            "(Chunk again/RB ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk all/PDT)\n",
            "(Chunk areas/NNS --/:)\n",
            "(Chunk disruption/NN)\n",
            "(Chunk terror/NN networks/NNS ,/,)\n",
            "(Chunk victory/NN)\n",
            "(Chunk Iraq/NNP ,/,)\n",
            "(Chunk spread/NN)\n",
            "(Chunk freedom/NN and/CC hope/NN)\n",
            "(Chunk troubled/JJ regions/NNS --/: we/PRP)\n",
            "(Chunk support/NN)\n",
            "(Chunk our/PRP$ friends/NNS and/CC allies/NNS ./.)\n",
            "(Chunk support/NN ,/, we/PRP must/MD always/RB)\n",
            "(Chunk clear/JJ)\n",
            "(Chunk our/PRP$ principles/NNS and/CC willing/JJ)\n",
            "(Chunk ./.)\n",
            "(Chunk only/JJ alternative/NN)\n",
            "(Chunk American/JJ leadership/NN)\n",
            "(Chunk\n",
            "  dramatically/RB\n",
            "  more/RBR\n",
            "  dangerous/JJ\n",
            "  and/CC\n",
            "  anxious/JJ\n",
            "  world/NN\n",
            "  ./.)\n",
            "(Chunk Yet/CC we/PRP also/RB)\n",
            "(Chunk it/PRP)\n",
            "(Chunk privilege/NN)\n",
            "(Chunk values/NNS that/WDT)\n",
            "(Chunk us/PRP birth/NN ./.)\n",
            "(Chunk American/JJ leaders/NNS --/:)\n",
            "(Chunk Roosevelt/NNP)\n",
            "(Chunk Truman/NNP)\n",
            "(Chunk Kennedy/NNP)\n",
            "(Chunk Reagan/NNP --/:)\n",
            "(Chunk isolation/NN and/CC retreat/NN ,/,)\n",
            "(Chunk they/PRP)\n",
            "(Chunk America/NNP)\n",
            "(Chunk always/RB more/RBR secure/JJ when/WRB freedom/NN)\n",
            "(Chunk march/NN ./.)\n",
            "(Chunk Our/PRP$ own/JJ generation/NN)\n",
            "(Chunk long/JJ war/NN)\n",
            "(Chunk determined/JJ enemy/NN --/:)\n",
            "(Chunk war/NN that/WDT will/MD)\n",
            "(Chunk Presidents/NNS)\n",
            "(Chunk parties/NNS ,/, who/WP will/MD)\n",
            "(Chunk steady/JJ bipartisan/JJ support/NN)\n",
            "(Chunk Congress/NNP ./.)\n",
            "(Chunk And/CC tonight/NN I/PRP)\n",
            "(Chunk yours/NNS ./.)\n",
            "(Chunk Together/RB ,/,)\n",
            "(Chunk us/PRP)\n",
            "(Chunk our/PRP$ country/NN ,/,)\n",
            "(Chunk men/NNS and/CC women/NNS who/WP)\n",
            "(Chunk us/PRP ,/, and/CC)\n",
            "(Chunk world/NN)\n",
            "(Chunk freedom/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Here/RB)\n",
            "(Chunk home/NN ,/, America/NNP also/RB)\n",
            "(Chunk great/JJ opportunity/NN :/: We/PRP will/MD)\n",
            "(Chunk prosperity/NN)\n",
            "(Chunk our/PRP$ country/NN)\n",
            "(Chunk our/PRP$ economic/JJ leadership/NN)\n",
            "(Chunk world/NN ./.)\n",
            "(Chunk Our/PRP$ economy/NN)\n",
            "(Chunk healthy/JJ and/CC vigorous/JJ ,/, and/CC)\n",
            "(Chunk faster/RBR)\n",
            "(Chunk other/JJ major/JJ)\n",
            "(Chunk nations/NNS ./.)\n",
            "(Chunk last/JJ two-and-a-half/JJ years/NNS ,/, America/NNP)\n",
            "(Chunk 4.6/CD million/CD new/JJ jobs/NNS --/: more/JJR)\n",
            "(Chunk Japan/NNP and/CC)\n",
            "(Chunk European/NNP Union/NNP)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Even/RB)\n",
            "(Chunk face/NN)\n",
            "(Chunk\n",
            "  higher/JJR\n",
            "  energy/NN\n",
            "  prices/NNS\n",
            "  and/CC\n",
            "  natural/JJ\n",
            "  disasters/NNS\n",
            "  ,/,)\n",
            "(Chunk American/JJ people/NNS)\n",
            "(Chunk economic/JJ performance/NN that/WDT)\n",
            "(Chunk envy/NN)\n",
            "(Chunk world/NN ./.)\n",
            "(Chunk American/JJ economy/NN)\n",
            "(Chunk preeminent/JJ ,/, but/CC we/PRP can/MD not/RB)\n",
            "(Chunk complacent/JJ ./.)\n",
            "(Chunk dynamic/JJ world/NN economy/NN ,/, we/PRP)\n",
            "(Chunk new/JJ competitors/NNS ,/,)\n",
            "(Chunk China/NNP and/CC India/NNP ,/, and/CC)\n",
            "(Chunk uncertainty/NN ,/, which/WDT)\n",
            "(Chunk it/PRP easier/JJR)\n",
            "(Chunk people/NNS 's/POS fears/NNS ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk old/JJ temptations/NNS return/NN ./.)\n",
            "(Chunk Protectionists/NNS)\n",
            "(Chunk competition/NN ,/,)\n",
            "(Chunk we/PRP can/MD)\n",
            "(Chunk our/PRP$ high/JJ standard/NN)\n",
            "(Chunk living/NN)\n",
            "(Chunk off/RP our/PRP$ economy/NN ./.)\n",
            "(Chunk Others/NNS)\n",
            "(Chunk government/NN)\n",
            "(Chunk larger/JJR role/NN)\n",
            "(Chunk economy/NN ,/,)\n",
            "(Chunk more/JJR power/NN)\n",
            "(Chunk Washington/NNP and/CC)\n",
            "(Chunk taxes/NNS ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk claims/NNS)\n",
            "(Chunk immigrants/NNS)\n",
            "(Chunk somehow/RB bad/JJ)\n",
            "(Chunk economy/NN --/: even/RB)\n",
            "(Chunk economy/NN could/MD not/RB)\n",
            "(Chunk them/PRP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk All/PDT)\n",
            "(Chunk forms/NNS)\n",
            "(Chunk economic/JJ retreat/NN ,/, and/CC they/PRP)\n",
            "(Chunk same/JJ direction/NN --/:)\n",
            "(Chunk stagnant/JJ and/CC second-rate/JJ economy/NN ./.)\n",
            "(Chunk Tonight/NNP I/PRP will/MD)\n",
            "(Chunk out/RP)\n",
            "(Chunk better/JJR path/NN :/:)\n",
            "(Chunk agenda/NN)\n",
            "(Chunk nation/NN that/WDT)\n",
            "(Chunk confidence/NN ;/:)\n",
            "(Chunk agenda/NN that/WDT will/MD)\n",
            "(Chunk standards/NNS)\n",
            "(Chunk living/NN and/CC)\n",
            "(Chunk new/JJ jobs/NNS ./.)\n",
            "(Chunk Americans/NNPS should/MD not/RB)\n",
            "(Chunk our/PRP$ economic/JJ future/NN ,/,)\n",
            "(Chunk we/PRP)\n",
            "(Chunk it/PRP ./.)\n",
            "(Chunk America/NNP competitive/JJ begins/NNS)\n",
            "(Chunk our/PRP$ economy/NN)\n",
            "(Chunk ./.)\n",
            "(Chunk And/CC our/PRP$ economy/NN)\n",
            "(Chunk when/WRB Americans/NNPS)\n",
            "(Chunk more/JJR)\n",
            "(Chunk their/PRP$ own/JJ money/NN)\n",
            "(Chunk ,/,)\n",
            "(Chunk ,/, and/CC invest/JJS ./.)\n",
            "(Chunk last/JJ five/CD years/NNS ,/,)\n",
            "(Chunk tax/NN relief/NN you/PRP)\n",
            "(Chunk $/$ 880/CD billion/CD)\n",
            "(Chunk hands/NNS)\n",
            "(Chunk\n",
            "  American/JJ\n",
            "  workers/NNS\n",
            "  ,/,\n",
            "  investors/NNS\n",
            "  ,/,\n",
            "  small/JJ\n",
            "  businesses/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  families/NNS\n",
            "  --/:\n",
            "  and/CC\n",
            "  they/PRP)\n",
            "(Chunk it/PRP)\n",
            "(Chunk more/JJR)\n",
            "(Chunk four/CD years/NNS)\n",
            "(Chunk uninterrupted/JJ economic/JJ growth/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Yet/RB)\n",
            "(Chunk tax/NN relief/NN)\n",
            "(Chunk next/JJ few/JJ years/NNS ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk nothing/NN ,/, American/NNP families/NNS will/MD)\n",
            "(Chunk massive/JJ tax/NN increase/NN they/PRP)\n",
            "(Chunk not/RB)\n",
            "(Chunk and/CC will/MD not/RB)\n",
            "(Chunk ./.)\n",
            "(Chunk America/NNP)\n",
            "(Chunk more/JJR)\n",
            "(Chunk temporary/JJ expansion/NN ,/, we/PRP)\n",
            "(Chunk more/JJR)\n",
            "(Chunk temporary/JJ tax/NN relief/NN ./.)\n",
            "(Chunk I/PRP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk responsibly/RB ,/, and/CC)\n",
            "(Chunk tax/NN cuts/NNS permanent/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP competitive/JJ)\n",
            "(Chunk us/PRP)\n",
            "(Chunk good/JJ stewards/NNS)\n",
            "(Chunk tax/NN dollars/NNS ./.)\n",
            "(Chunk year/NN)\n",
            "(Chunk my/PRP$ presidency/NN ,/, we/PRP)\n",
            "(Chunk growth/NN)\n",
            "(Chunk\n",
            "  non-security/JJ\n",
            "  discretionary/JJ\n",
            "  spending/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  last/JJ\n",
            "  year/NN\n",
            "  you/PRP)\n",
            "(Chunk bills/NNS)\n",
            "(Chunk spending/NN ./.)\n",
            "(Chunk year/NN my/PRP$ budget/NN will/MD)\n",
            "(Chunk it/PRP again/RB ,/, and/CC)\n",
            "(Chunk or/CC)\n",
            "(Chunk more/JJR)\n",
            "(Chunk 140/CD programs/NNS that/WDT)\n",
            "(Chunk\n",
            "  poorly/RB\n",
            "  or/CC\n",
            "  not/RB\n",
            "  fulfilling/JJ\n",
            "  essential/JJ\n",
            "  priorities/NNS\n",
            "  ./.)\n",
            "(Chunk reforms/NNS ,/, we/PRP will/MD)\n",
            "(Chunk American/NNP taxpayer/NN)\n",
            "(Chunk $/$ 14/CD billion/CD next/JJ year/NN ,/, and/CC)\n",
            "(Chunk track/NN)\n",
            "(Chunk deficit/NN)\n",
            "(Chunk half/NN)\n",
            "(Chunk 2009/CD ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk I/PRP)\n",
            "(Chunk pleased/JJ)\n",
            "(Chunk members/NNS)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk earmark/NN reform/NN ,/,)\n",
            "(Chunk federal/JJ budget/NN)\n",
            "(Chunk too/RB many/JJ special/JJ interest/NN projects/NNS ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk And/CC we/PRP can/MD)\n",
            "(Chunk problem/NN together/RB ,/,)\n",
            "(Chunk you/PRP)\n",
            "(Chunk line-item/JJ veto/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk We/PRP must/MD also/RB)\n",
            "(Chunk larger/JJR challenge/NN)\n",
            "(Chunk mandatory/JJ spending/NN ,/, or/CC entitlements/NNS ./.)\n",
            "(Chunk year/NN ,/,)\n",
            "(Chunk first/JJ)\n",
            "(Chunk about/RB 78/CD million/CD baby/NN boomers/NNS)\n",
            "(Chunk 60/CD ,/,)\n",
            "(Chunk two/CD)\n",
            "(Chunk\n",
            "  my/PRP$\n",
            "  Dad/NNP\n",
            "  's/POS\n",
            "  favorite/JJ\n",
            "  people/NNS\n",
            "  --/:\n",
            "  me/PRP\n",
            "  and/CC\n",
            "  President/NNP\n",
            "  Clinton/NNP\n",
            "  ./.)\n",
            "(Chunk (/( Laughter/NNP ./. )/))\n",
            "(Chunk milestone/NN)\n",
            "(Chunk more/JJR)\n",
            "(Chunk personal/JJ crisis/NN --/: (/( laughter/NN )/) --/: it/PRP)\n",
            "(Chunk national/JJ challenge/NN ./.)\n",
            "(Chunk retirement/NN)\n",
            "(Chunk baby/NN boom/NN generation/NN will/MD)\n",
            "(Chunk unprecedented/JJ strains/NNS)\n",
            "(Chunk federal/JJ government/NN ./.)\n",
            "(Chunk 2030/CD ,/,)\n",
            "(Chunk\n",
            "  Social/NNP\n",
            "  Security/NNP\n",
            "  ,/,\n",
            "  Medicare/NNP\n",
            "  and/CC\n",
            "  Medicaid/NNP\n",
            "  alone/RB\n",
            "  will/MD)\n",
            "(Chunk almost/RB 60/CD percent/NN)\n",
            "(Chunk entire/JJ federal/JJ budget/NN ./.)\n",
            "(Chunk And/CC)\n",
            "(Chunk will/MD)\n",
            "(Chunk future/JJ Congresses/NNS)\n",
            "(Chunk impossible/JJ choices/NNS --/:)\n",
            "(Chunk\n",
            "  tax/NN\n",
            "  increases/NNS\n",
            "  ,/,\n",
            "  immense/JJ\n",
            "  deficits/NNS\n",
            "  ,/,\n",
            "  or/CC\n",
            "  deep/JJ\n",
            "  cuts/NNS)\n",
            "(Chunk category/NN)\n",
            "(Chunk spending/NN ./.)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk not/RB)\n",
            "(Chunk last/JJ year/NN)\n",
            "(Chunk my/PRP$ proposal/NN)\n",
            "(Chunk Social/NNP Security/NNP --/: (/( applause/NN )/) --/: yet/RB)\n",
            "(Chunk cost/NN)\n",
            "(Chunk entitlements/NNS)\n",
            "(Chunk problem/NN that/WDT)\n",
            "(Chunk not/RB)\n",
            "(Chunk away/RB ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk And/CC)\n",
            "(Chunk year/NN we/PRP)\n",
            "(Chunk ,/,)\n",
            "(Chunk situation/NN)\n",
            "(Chunk worse/JJR ./.)\n",
            "(Chunk So/RB tonight/JJ ,/, I/PRP)\n",
            "(Chunk you/PRP)\n",
            "(Chunk me/PRP)\n",
            "(Chunk commission/NN)\n",
            "(Chunk full/JJ impact/NN)\n",
            "(Chunk baby/NN boom/NN retirements/NNS)\n",
            "(Chunk\n",
            "  Social/NNP\n",
            "  Security/NNP\n",
            "  ,/,\n",
            "  Medicare/NNP\n",
            "  ,/,\n",
            "  and/CC\n",
            "  Medicaid/NNP\n",
            "  ./.)\n",
            "(Chunk commission/NN should/MD)\n",
            "(Chunk members/NNS)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk parties/NNS ,/, and/CC)\n",
            "(Chunk bipartisan/JJ solutions/NNS ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk\n",
            "  aside/RP\n",
            "  partisan/JJ\n",
            "  politics/NNS\n",
            "  and/CC\n",
            "  work/NN\n",
            "  together/RB\n",
            "  and/CC)\n",
            "(Chunk problem/NN)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP competitive/JJ)\n",
            "(Chunk us/PRP)\n",
            "(Chunk more/JJR markets/NNS)\n",
            "(Chunk Americans/NNPS)\n",
            "(Chunk and/CC)\n",
            "(Chunk ./.)\n",
            "(Chunk One/CD out/NN)\n",
            "(Chunk five/CD factory/NN jobs/NNS)\n",
            "(Chunk America/NNP)\n",
            "(Chunk global/JJ trade/NN ,/, and/CC we/PRP)\n",
            "(Chunk people/NNS everywhere/RB)\n",
            "(Chunk American/NNP ./.)\n",
            "(Chunk open/JJ markets/NNS and/CC)\n",
            "(Chunk level/JJ playing/NN field/NN ,/,)\n",
            "(Chunk one/NN can/MD)\n",
            "(Chunk or/CC)\n",
            "(Chunk American/JJ worker/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP competitive/JJ)\n",
            "(Chunk immigration/NN system/NN that/WDT)\n",
            "(Chunk our/PRP$ laws/NNS ,/,)\n",
            "(Chunk our/PRP$ values/NNS ,/, and/CC)\n",
            "(Chunk interests/NNS)\n",
            "(Chunk our/PRP$ economy/NN ./.)\n",
            "(Chunk Our/PRP$ nation/NN)\n",
            "(Chunk orderly/JJ and/CC secure/JJ borders/NNS ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk goal/NN ,/, we/PRP must/MD)\n",
            "(Chunk\n",
            "  stronger/JJR\n",
            "  immigration/NN\n",
            "  enforcement/NN\n",
            "  and/CC\n",
            "  border/NN\n",
            "  protection/NN\n",
            "  ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk And/CC we/PRP must/MD)\n",
            "(Chunk\n",
            "  rational/JJ\n",
            "  ,/,\n",
            "  humane/JJ\n",
            "  guest/JJS\n",
            "  worker/NN\n",
            "  program/NN\n",
            "  that/WDT)\n",
            "(Chunk amnesty/JJ ,/,)\n",
            "(Chunk temporary/JJ jobs/NNS)\n",
            "(Chunk people/NNS who/WP)\n",
            "(Chunk them/PRP legally/RB ,/, and/CC reduces/NNS)\n",
            "(Chunk and/CC crime/NN)\n",
            "(Chunk border/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP competitive/JJ)\n",
            "(Chunk affordable/JJ health/NN care/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Our/PRP$ government/NN)\n",
            "(Chunk responsibility/NN)\n",
            "(Chunk health/NN care/NN)\n",
            "(Chunk poor/JJ and/CC)\n",
            "(Chunk elderly/JJ ,/, and/CC we/PRP)\n",
            "(Chunk responsibility/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Americans/NNPS --/:)\n",
            "(Chunk Americans/NNPS ,/, we/PRP must/MD)\n",
            "(Chunk cost/NN)\n",
            "(Chunk care/NN ,/,)\n",
            "(Chunk\n",
            "  doctor-patient/JJ\n",
            "  relationship/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  help/NN\n",
            "  people/NNS)\n",
            "(Chunk insurance/NN coverage/NN they/PRP)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk wider/JJR use/NN)\n",
            "(Chunk\n",
            "  electronic/JJ\n",
            "  records/NNS\n",
            "  and/CC\n",
            "  other/JJ\n",
            "  health/NN\n",
            "  information/NN\n",
            "  technology/NN\n",
            "  ,/,)\n",
            "(Chunk costs/NNS and/CC)\n",
            "(Chunk dangerous/JJ medical/JJ errors/NNS ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk health/NN savings/NNS accounts/NNS --/:)\n",
            "(Chunk\n",
            "  sure/JJ\n",
            "  individuals/NNS\n",
            "  and/CC\n",
            "  small/JJ\n",
            "  business/NN\n",
            "  employees/NNS\n",
            "  can/MD)\n",
            "(Chunk insurance/NN)\n",
            "(Chunk same/JJ)\n",
            "(Chunk people/NNS)\n",
            "(Chunk big/JJ businesses/NNS now/RB)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk more/JJR)\n",
            "(Chunk coverage/NN portable/JJ ,/,)\n",
            "(Chunk workers/NNS can/MD)\n",
            "(Chunk jobs/NNS)\n",
            "(Chunk their/PRP$ health/NN insurance/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk And/CC)\n",
            "(Chunk lawsuits/NNS)\n",
            "(Chunk many/JJ good/JJ doctors/NNS)\n",
            "(Chunk practice/NN --/:)\n",
            "(Chunk women/NNS)\n",
            "(Chunk nearly/RB 1,500/CD American/JJ counties/NNS)\n",
            "(Chunk single/JJ OB/GYN/NNP --/: I/PRP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk medical/JJ liability/NN reform/NN)\n",
            "(Chunk year/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk America/NNP competitive/JJ)\n",
            "(Chunk affordable/JJ energy/NN ./.)\n",
            "(Chunk And/CC here/RB we/PRP)\n",
            "(Chunk serious/JJ problem/NN :/: America/NNP)\n",
            "(Chunk oil/NN ,/, which/WDT)\n",
            "(Chunk often/RB)\n",
            "(Chunk unstable/JJ parts/NNS)\n",
            "(Chunk world/NN ./.)\n",
            "(Chunk best/JJS way/NN)\n",
            "(Chunk addiction/NN)\n",
            "(Chunk technology/NN ./.)\n",
            "(Chunk 2001/CD ,/, we/PRP)\n",
            "(Chunk nearly/RB $/$ 10/CD billion/CD)\n",
            "(Chunk\n",
            "  cleaner/JJR\n",
            "  ,/,\n",
            "  cheaper/JJR\n",
            "  ,/,\n",
            "  and/CC\n",
            "  more/RBR\n",
            "  reliable/JJ\n",
            "  alternative/JJ\n",
            "  energy/NN\n",
            "  sources/NNS\n",
            "  --/:\n",
            "  and/CC\n",
            "  we/PRP)\n",
            "(Chunk threshold/NN)\n",
            "(Chunk incredible/JJ advances/NNS ./.)\n",
            "(Chunk So/RB tonight/JJ ,/, I/PRP)\n",
            "(Chunk Advanced/NNP Energy/NNP Initiative/NNP --/:)\n",
            "(Chunk 22-percent/JJ increase/NN)\n",
            "(Chunk clean-energy/JJ research/NN --/:)\n",
            "(Chunk Department/NNP)\n",
            "(Chunk Energy/NNP ,/,)\n",
            "(Chunk breakthroughs/NNS)\n",
            "(Chunk two/CD vital/JJ areas/NNS ./.)\n",
            "(Chunk\n",
            "  how/WRB\n",
            "  we/PRP\n",
            "  power/NN\n",
            "  our/PRP$\n",
            "  homes/NNS\n",
            "  and/CC\n",
            "  offices/NNS\n",
            "  ,/,\n",
            "  we/PRP\n",
            "  will/MD)\n",
            "(Chunk more/RBR)\n",
            "(Chunk\n",
            "  zero-emission/JJ\n",
            "  coal-fired/JJ\n",
            "  plants/NNS\n",
            "  ,/,\n",
            "  revolutionary/JJ\n",
            "  solar/NN\n",
            "  and/CC\n",
            "  wind/NN\n",
            "  technologies/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  clean/JJ\n",
            "  ,/,\n",
            "  safe/JJ\n",
            "  nuclear/JJ\n",
            "  energy/NN\n",
            "  ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk We/PRP must/MD also/RB)\n",
            "(Chunk how/WRB we/PRP power/NN our/PRP$ automobiles/NNS ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk our/PRP$ research/NN)\n",
            "(Chunk better/JJR batteries/NNS)\n",
            "(Chunk hybrid/JJ and/CC electric/JJ cars/NNS ,/, and/CC)\n",
            "(Chunk pollution-free/JJ cars/NNS that/WDT)\n",
            "(Chunk hydrogen/NN ./.)\n",
            "(Chunk We/PRP 'll/MD also/RB)\n",
            "(Chunk additional/JJ research/NN)\n",
            "(Chunk cutting-edge/JJ methods/NNS)\n",
            "(Chunk ethanol/NN ,/, not/RB just/RB)\n",
            "(Chunk corn/NN ,/, but/CC)\n",
            "(Chunk wood/NN chips/NNS and/CC stalks/NNS ,/, or/CC)\n",
            "(Chunk grass/NN ./.)\n",
            "(Chunk Our/PRP$ goal/NN)\n",
            "(Chunk new/JJ kind/NN)\n",
            "(Chunk ethanol/JJ practical/JJ and/CC competitive/JJ)\n",
            "(Chunk six/CD years/NNS ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Breakthroughs/NNS)\n",
            "(Chunk and/CC other/JJ new/JJ technologies/NNS will/MD)\n",
            "(Chunk us/PRP)\n",
            "(Chunk great/JJ goal/NN :/:)\n",
            "(Chunk more/JJR)\n",
            "(Chunk 75/CD percent/NN)\n",
            "(Chunk our/PRP$ oil/NN imports/NNS)\n",
            "(Chunk Middle/NNP East/NNP)\n",
            "(Chunk 2025/CD ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk talent/NN and/CC technology/NN)\n",
            "(Chunk America/NNP ,/,)\n",
            "(Chunk country/NN can/MD dramatically/RB)\n",
            "(Chunk our/PRP$ environment/NN ,/,)\n",
            "(Chunk petroleum-based/JJ economy/NN ,/, and/CC)\n",
            "(Chunk our/PRP$ dependence/NN)\n",
            "(Chunk Middle/NNP Eastern/NNP oil/NN)\n",
            "(Chunk thing/NN)\n",
            "(Chunk past/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk And/CC)\n",
            "(Chunk America/NNP competitive/JJ ,/, one/CD commitment/NN)\n",
            "(Chunk necessary/JJ)\n",
            "(Chunk :/: We/PRP must/MD)\n",
            "(Chunk world/NN)\n",
            "(Chunk human/JJ talent/NN and/CC creativity/NN ./.)\n",
            "(Chunk Our/PRP$ greatest/JJS advantage/NN)\n",
            "(Chunk world/NN)\n",
            "(Chunk always/RB)\n",
            "(Chunk our/PRP$)\n",
            "(Chunk ,/,)\n",
            "(Chunk ,/, ambitious/JJ people/NNS --/: and/CC we/PRP)\n",
            "(Chunk edge/NN ./.)\n",
            "(Chunk Tonight/NN I/PRP)\n",
            "(Chunk American/JJ Competitiveness/NNP Initiative/NNP ,/,)\n",
            "(Chunk innovation/NN)\n",
            "(Chunk our/PRP$ economy/NN ,/, and/CC)\n",
            "(Chunk our/PRP$ nation/NN 's/POS children/NNS)\n",
            "(Chunk firm/NN)\n",
            "(Chunk math/NN and/CC science/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk First/RB ,/, I/PRP)\n",
            "(Chunk federal/JJ commitment/NN)\n",
            "(Chunk most/RBS critical/JJ basic/JJ research/NN programs/NNS)\n",
            "(Chunk physical/JJ sciences/NNS)\n",
            "(Chunk next/JJ 10/CD years/NNS ./.)\n",
            "(Chunk funding/NN will/MD)\n",
            "(Chunk work/NN)\n",
            "(Chunk America/NNP 's/POS most/RBS creative/JJ minds/NNS)\n",
            "(Chunk they/PRP)\n",
            "(Chunk areas/NNS such/JJ)\n",
            "(Chunk\n",
            "  nanotechnology/NN\n",
            "  ,/,\n",
            "  supercomputing/NN\n",
            "  ,/,\n",
            "  and/CC\n",
            "  alternative/JJ\n",
            "  energy/NN\n",
            "  sources/NNS\n",
            "  ./.)\n",
            "(Chunk Second/JJ ,/, I/PRP)\n",
            "(Chunk permanent/JJ)\n",
            "(Chunk\n",
            "  research/NN\n",
            "  and/CC\n",
            "  development/NN\n",
            "  tax/NN\n",
            "  credit/NN\n",
            "  --/:\n",
            "  (/(\n",
            "  applause/NN\n",
            "  )/)\n",
            "  --/:)\n",
            "(Chunk private-sector/JJ initiatives/NNS)\n",
            "(Chunk technology/NN ./.)\n",
            "(Chunk more/JJR research/NN)\n",
            "(Chunk both/CC)\n",
            "(Chunk public/NN and/CC private/JJ sectors/NNS ,/, we/PRP will/MD)\n",
            "(Chunk our/PRP$ quality/NN)\n",
            "(Chunk life/NN --/: and/CC)\n",
            "(Chunk America/NNP will/MD)\n",
            "(Chunk world/NN)\n",
            "(Chunk opportunity/NN and/CC innovation/NN)\n",
            "(Chunk decades/NNS)\n",
            "(Chunk ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Third/NNP ,/, we/PRP)\n",
            "(Chunk children/NNS)\n",
            "(Chunk more/JJR math/NN and/CC science/NN ,/, and/CC)\n",
            "(Chunk sure/JJ)\n",
            "(Chunk courses/NNS)\n",
            "(Chunk rigorous/JJ enough/RB)\n",
            "(Chunk other/JJ nations/NNS ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk good/JJ start/NN)\n",
            "(Chunk early/JJ grades/NNS)\n",
            "(Chunk No/NNP Child/NNP Left/NNP Behind/NNP Act/NNP ,/, which/WDT)\n",
            "(Chunk standards/NNS and/CC)\n",
            "(Chunk test/NN scores/NNS)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk Tonight/NNP I/PRP)\n",
            "(Chunk 70,000/CD high/JJ school/NN teachers/NNS)\n",
            "(Chunk advanced-placement/JJ courses/NNS)\n",
            "(Chunk math/NN and/CC science/NN ,/,)\n",
            "(Chunk 30,000/CD math/NN and/CC science/NN professionals/NNS)\n",
            "(Chunk classrooms/NNS ,/, and/CC)\n",
            "(Chunk early/JJ help/NN)\n",
            "(Chunk students/NNS who/WP)\n",
            "(Chunk math/NN ,/,)\n",
            "(Chunk they/PRP)\n",
            "(Chunk better/JJR chance/NN)\n",
            "(Chunk good/JJ ,/, high-wage/JJ jobs/NNS ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk America/NNP 's/POS children/NNS)\n",
            "(Chunk life/NN ,/, they/PRP will/MD)\n",
            "(Chunk America/NNP)\n",
            "(Chunk world/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk our/PRP$ nation/NN)\n",
            "(Chunk world/NN)\n",
            "(Chunk goal/NN)\n",
            "(Chunk us/PRP can/MD share/NN ./.)\n",
            "(Chunk I/PRP)\n",
            "(Chunk you/PRP)\n",
            "(Chunk\n",
            "  American/JJ\n",
            "  Competitiveness/NNP\n",
            "  Initiative/NNP\n",
            "  ,/,\n",
            "  and/CC\n",
            "  together/RB\n",
            "  we/PRP\n",
            "  will/MD)\n",
            "(Chunk world/NN what/WP)\n",
            "(Chunk American/JJ people/NNS can/MD)\n",
            "(Chunk ./.)\n",
            "(Chunk America/NNP)\n",
            "(Chunk great/JJ force/NN)\n",
            "(Chunk freedom/NN and/CC prosperity/NN ./.)\n",
            "(Chunk Yet/RB our/PRP$ greatness/NN)\n",
            "(Chunk not/RB)\n",
            "(Chunk power/NN or/CC luxuries/NNS ,/, but/CC)\n",
            "(Chunk who/WP we/PRP)\n",
            "(Chunk and/CC how/WRB we/PRP)\n",
            "(Chunk one/CD)\n",
            "(Chunk ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk compassionate/NN ,/, decent/NN ,/, hopeful/JJ society/NN ./.)\n",
            "(Chunk recent/JJ years/NNS ,/, America/NNP)\n",
            "(Chunk more/RBR hopeful/JJ nation/NN ./.)\n",
            "(Chunk Violent/JJ crime/NN rates/NNS)\n",
            "(Chunk their/PRP$ lowest/JJS levels/NNS)\n",
            "(Chunk 1970s/CD ./.)\n",
            "(Chunk Welfare/NN cases/NNS)\n",
            "(Chunk more/JJR)\n",
            "(Chunk half/NN)\n",
            "(Chunk past/JJ decade/NN ./.)\n",
            "(Chunk Drug/NN use/NN)\n",
            "(Chunk youth/NN)\n",
            "(Chunk down/RB 19/CD percent/NN)\n",
            "(Chunk 2001/CD ./.)\n",
            "(Chunk There/EX)\n",
            "(Chunk fewer/JJR abortions/NNS)\n",
            "(Chunk America/NNP)\n",
            "(Chunk point/NN)\n",
            "(Chunk last/JJ three/CD decades/NNS ,/, and/CC)\n",
            "(Chunk number/NN)\n",
            "(Chunk children/NNS)\n",
            "(Chunk mothers/NNS)\n",
            "(Chunk dozen/NN years/NNS)\n",
            "(Chunk row/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk gains/NNS)\n",
            "(Chunk evidence/NN)\n",
            "(Chunk quiet/JJ transformation/NN --/:)\n",
            "(Chunk revolution/NN)\n",
            "(Chunk conscience/NN ,/,)\n",
            "(Chunk which/WDT)\n",
            "(Chunk generation/NN)\n",
            "(Chunk life/NN)\n",
            "(Chunk personal/JJ responsibility/NN)\n",
            "(Chunk life/NN)\n",
            "(Chunk fulfillment/NN ./.)\n",
            "(Chunk Government/NNP)\n",
            "(Chunk role/NN ./.)\n",
            "(Chunk Wise/NNP policies/NNS ,/, such/JJ)\n",
            "(Chunk\n",
            "  welfare/NN\n",
            "  reform/NN\n",
            "  and/CC\n",
            "  drug/NN\n",
            "  education/NN\n",
            "  and/CC\n",
            "  support/NN)\n",
            "(Chunk abstinence/NN and/CC adoption/NN)\n",
            "(Chunk difference/NN)\n",
            "(Chunk character/NN)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk\n",
            "  And/CC\n",
            "  everyone/NN\n",
            "  here/RB\n",
            "  tonight/RB\n",
            "  ,/,\n",
            "  Democrat/NNP\n",
            "  and/CC\n",
            "  Republican/NNP\n",
            "  ,/,)\n",
            "(Chunk right/NN)\n",
            "(Chunk proud/JJ)\n",
            "(Chunk record/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk\n",
            "  Yet/RB\n",
            "  many/JJ\n",
            "  Americans/NNPS\n",
            "  ,/,\n",
            "  especially/RB\n",
            "  parents/NNS\n",
            "  ,/,\n",
            "  still/RB)\n",
            "(Chunk deep/JJ concerns/NNS)\n",
            "(Chunk direction/NN)\n",
            "(Chunk our/PRP$ culture/NN ,/, and/CC)\n",
            "(Chunk health/NN)\n",
            "(Chunk our/PRP$ most/JJS basic/JJ institutions/NNS ./.)\n",
            "(Chunk They/PRP)\n",
            "(Chunk unethical/JJ conduct/NN)\n",
            "(Chunk public/JJ officials/NNS ,/, and/CC)\n",
            "(Chunk activist/NN courts/NNS that/WDT)\n",
            "(Chunk marriage/NN ./.)\n",
            "(Chunk They/PRP)\n",
            "(Chunk children/NNS)\n",
            "(Chunk our/PRP$ society/NN who/WP)\n",
            "(Chunk direction/NN and/CC love/NN ,/, and/CC)\n",
            "(Chunk fellow/JJ citizens/NNS still/RB)\n",
            "(Chunk natural/JJ disaster/NN ,/, and/CC)\n",
            "(Chunk treatable/JJ diseases/NNS ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk challenges/NNS ,/, we/PRP must/MD never/RB)\n",
            "(Chunk belief/NN)\n",
            "(Chunk America/NNP)\n",
            "(Chunk decline/NN ,/, or/CC)\n",
            "(Chunk our/PRP$ culture/NN)\n",
            "(Chunk ./.)\n",
            "(Chunk American/JJ people/NNS)\n",
            "(Chunk better/JJR)\n",
            "(Chunk ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk pessimists/NNS wrong/JJ before/RB --/: and/CC we/PRP will/MD)\n",
            "(Chunk it/PRP again/RB ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk hopeful/JJ society/NN)\n",
            "(Chunk courts/NNS)\n",
            "(Chunk equal/JJ justice/NN)\n",
            "(Chunk law/NN ./.)\n",
            "(Chunk Supreme/NNP Court/NNP now/RB)\n",
            "(Chunk two/CD superb/JJ new/JJ members/NNS --/: new/JJ members/NNS)\n",
            "(Chunk\n",
            "  its/PRP$\n",
            "  bench/NN\n",
            "  :/:\n",
            "  Chief/JJ\n",
            "  Justice/NNP\n",
            "  John/NNP\n",
            "  Roberts/NNP\n",
            "  and/CC\n",
            "  Justice/NNP\n",
            "  Sam/NNP\n",
            "  Alito/NNP\n",
            "  ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk I/PRP)\n",
            "(Chunk Senate/NNP)\n",
            "(Chunk them/PRP ./.)\n",
            "(Chunk I/PRP will/MD)\n",
            "(Chunk men/NNS and/CC women/NNS who/WP)\n",
            "(Chunk judges/NNS must/MD)\n",
            "(Chunk servants/NNS)\n",
            "(Chunk law/NN ,/, and/CC not/RB)\n",
            "(Chunk bench/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Today/NN)\n",
            "(Chunk official/JJ retirement/NN)\n",
            "(Chunk very/RB special/JJ American/NNP ./.)\n",
            "(Chunk 24/CD years/NNS)\n",
            "(Chunk faithful/JJ service/NN)\n",
            "(Chunk our/PRP$ nation/NN ,/,)\n",
            "(Chunk United/NNP States/NNPS)\n",
            "(Chunk grateful/JJ)\n",
            "(Chunk Justice/NNP Sandra/NNP Day/NNP O'Connor/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk hopeful/JJ society/NN)\n",
            "(Chunk institutions/NNS)\n",
            "(Chunk science/NN and/CC medicine/NN that/WDT)\n",
            "(Chunk not/RB)\n",
            "(Chunk ethical/JJ corners/NNS ,/, and/CC)\n",
            "(Chunk matchless/NN value/NN)\n",
            "(Chunk life/NN ./.)\n",
            "(Chunk Tonight/NNP I/PRP)\n",
            "(Chunk you/PRP)\n",
            "(Chunk legislation/NN)\n",
            "(Chunk most/RBS egregious/JJ abuses/NNS)\n",
            "(Chunk medical/JJ research/NN :/: human/JJ)\n",
            "(Chunk its/PRP$ forms/NNS ,/,)\n",
            "(Chunk or/CC)\n",
            "(Chunk embryos/NN)\n",
            "(Chunk experiments/NNS ,/,)\n",
            "(Chunk\n",
            "  human-animal/JJ\n",
            "  hybrids/NNS\n",
            "  ,/,\n",
            "  and/CC\n",
            "  buying/NN\n",
            "  ,/,\n",
            "  selling/NN\n",
            "  ,/,\n",
            "  or/CC)\n",
            "(Chunk human/JJ embryos/NN ./.)\n",
            "(Chunk Human/NNP life/NN)\n",
            "(Chunk gift/NN)\n",
            "(Chunk our/PRP$ Creator/NNP --/: and/CC)\n",
            "(Chunk gift/NN should/MD never/RB)\n",
            "(Chunk ,/,)\n",
            "(Chunk or/CC)\n",
            "(Chunk up/RP)\n",
            "(Chunk sale/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk hopeful/JJ society/NN)\n",
            "(Chunk officials/NNS)\n",
            "(Chunk public/JJ trust/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Honorable/JJ people/NNS)\n",
            "(Chunk parties/NNS)\n",
            "(Chunk reforms/NNS)\n",
            "(Chunk ethical/JJ standards/NNS)\n",
            "(Chunk Washington/NNP --/: I/PRP)\n",
            "(Chunk your/PRP$ efforts/NNS ./.)\n",
            "(Chunk us/PRP)\n",
            "(Chunk pledge/NN)\n",
            "(Chunk worthy/JJ)\n",
            "(Chunk public/JJ responsibility/NN --/: and/CC)\n",
            "(Chunk pledge/NN we/PRP must/MD never/RB)\n",
            "(Chunk ,/, never/RB dismiss/NN ,/, and/CC never/RB betray/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk we/PRP)\n",
            "(Chunk promise/NN)\n",
            "(Chunk our/PRP$ institutions/NNS ,/,)\n",
            "(Chunk us/PRP also/RB)\n",
            "(Chunk character/NN)\n",
            "(Chunk America/NNP)\n",
            "(Chunk our/PRP$ compassion/NN and/CC care/NN)\n",
            "(Chunk one/CD)\n",
            "(Chunk ./.)\n",
            "(Chunk hopeful/JJ society/NN)\n",
            "(Chunk special/JJ attention/NN)\n",
            "(Chunk children/NNS who/WP)\n",
            "(Chunk direction/NN and/CC love/NN ./.)\n",
            "(Chunk\n",
            "  Helping/NNP\n",
            "  America/NNP\n",
            "  's/POS\n",
            "  Youth/NNP\n",
            "  Initiative/NNP\n",
            "  ,/,\n",
            "  we/PRP)\n",
            "(Chunk adults/NNS)\n",
            "(Chunk life/NN)\n",
            "(Chunk child/NN --/: and/CC)\n",
            "(Chunk good/JJ work/NN)\n",
            "(Chunk our/PRP$ First/NNP Lady/NNP ,/, Laura/NNP Bush/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk year/NN we/PRP will/MD)\n",
            "(Chunk resources/NNS)\n",
            "(Chunk young/JJ people/NNS)\n",
            "(Chunk school/NN ,/, so/RB more/JJR)\n",
            "(Chunk America/NNP 's/POS youth/NN can/MD)\n",
            "(Chunk their/PRP$ sights/NNS and/CC)\n",
            "(Chunk their/PRP$ dreams/NNS ./.)\n",
            "(Chunk hopeful/JJ society/NN)\n",
            "(Chunk aid/NN)\n",
            "(Chunk fellow/JJ citizens/NNS)\n",
            "(Chunk times/NNS)\n",
            "(Chunk suffering/NN and/CC emergency/NN --/: and/CC stays/NNS)\n",
            "(Chunk it/PRP)\n",
            "(Chunk they/PRP)\n",
            "(Chunk back/RB)\n",
            "(Chunk their/PRP$ feet/NNS ./.)\n",
            "(Chunk So/RB far/RB)\n",
            "(Chunk federal/JJ government/NN)\n",
            "(Chunk $/$ 85/CD billion/CD)\n",
            "(Chunk people/NNS)\n",
            "(Chunk Gulf/NNP Coast/NNP and/CC New/NNP Orleans/NNP ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk debris/NN and/CC repairing/NN highways/NNS and/CC)\n",
            "(Chunk stronger/JJR levees/NNS ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk business/NN loans/NNS and/CC housing/NN assistance/NN ./.)\n",
            "(Chunk Yet/RB)\n",
            "(Chunk we/PRP)\n",
            "(Chunk immediate/JJ needs/NNS ,/, we/PRP must/MD also/RB)\n",
            "(Chunk deeper/JJR challenges/NNS that/WDT)\n",
            "(Chunk storm/NN)\n",
            "(Chunk ./.)\n",
            "(Chunk New/NNP Orleans/NNP and/CC)\n",
            "(Chunk other/JJ places/NNS ,/, many/JJ)\n",
            "(Chunk our/PRP$ fellow/JJ citizens/NNS)\n",
            "(Chunk promise/NN)\n",
            "(Chunk our/PRP$ country/NN ./.)\n",
            "(Chunk answer/NN)\n",
            "(Chunk\n",
            "  not/RB\n",
            "  only/RB\n",
            "  temporary/JJ\n",
            "  relief/NN\n",
            "  ,/,\n",
            "  but/CC\n",
            "  schools/NNS\n",
            "  that/WDT)\n",
            "(Chunk child/NN ,/, and/CC job/NN skills/NNS)\n",
            "(Chunk upward/JJ mobility/NN ,/, and/CC more/JJR opportunities/NNS)\n",
            "(Chunk home/NN and/CC)\n",
            "(Chunk business/NN ./.)\n",
            "(Chunk we/PRP)\n",
            "(Chunk disaster/NN ,/,)\n",
            "(Chunk us/PRP also/RB work/NN)\n",
            "(Chunk day/NN when/WRB)\n",
            "(Chunk Americans/NNPS)\n",
            "(Chunk justice/NN ,/, equal/JJ)\n",
            "(Chunk hope/NN ,/, and/CC rich/JJ)\n",
            "(Chunk opportunity/NN ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk hopeful/JJ society/NN acts/NNS boldly/RB)\n",
            "(Chunk diseases/NNS)\n",
            "(Chunk HIV/AIDS/NNP ,/, which/WDT can/MD)\n",
            "(Chunk ,/, and/CC)\n",
            "(Chunk ,/, and/CC)\n",
            "(Chunk ./.)\n",
            "(Chunk More/JJR)\n",
            "(Chunk million/CD Americans/NNPS)\n",
            "(Chunk HIV/NNP ,/, and/CC half/NN)\n",
            "(Chunk AIDS/NNP cases/NNS)\n",
            "(Chunk African/JJ Americans/NNPS ./.)\n",
            "(Chunk I/PRP)\n",
            "(Chunk Congress/NNP)\n",
            "(Chunk and/CC)\n",
            "(Chunk Ryan/NNP White/NNP Act/NNP ,/, and/CC)\n",
            "(Chunk new/JJ funding/NN)\n",
            "(Chunk states/NNS ,/,)\n",
            "(Chunk we/PRP)\n",
            "(Chunk waiting/NN lists/NNS)\n",
            "(Chunk AIDS/NNP medicines/NNS)\n",
            "(Chunk America/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk We/PRP will/MD also/RB)\n",
            "(Chunk nationwide/JJ effort/NN ,/,)\n",
            "(Chunk closely/RB)\n",
            "(Chunk\n",
            "  African/JJ\n",
            "  American/JJ\n",
            "  churches/NNS\n",
            "  and/CC\n",
            "  faith-based/JJ\n",
            "  groups/NNS\n",
            "  ,/,)\n",
            "(Chunk rapid/JJ HIV/NNP tests/NNS)\n",
            "(Chunk millions/NNS ,/,)\n",
            "(Chunk stigma/NN)\n",
            "(Chunk AIDS/NNP ,/, and/CC)\n",
            "(Chunk closer/JJR)\n",
            "(Chunk day/NN when/WRB there/EX)\n",
            "(Chunk new/JJ infections/NNS)\n",
            "(Chunk America/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n",
            "(Chunk Fellow/NNP citizens/NNS ,/, we/PRP)\n",
            "(Chunk leadership/NN)\n",
            "(Chunk period/NN)\n",
            "(Chunk consequence/NN ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk great/JJ ideological/JJ conflict/NN we/PRP)\n",
            "(Chunk nothing/NN)\n",
            "(Chunk ./.)\n",
            "(Chunk We/PRP)\n",
            "(Chunk great/JJ changes/NNS)\n",
            "(Chunk science/NN and/CC commerce/NN that/WDT will/MD)\n",
            "(Chunk our/PRP$ lives/NNS ./.)\n",
            "(Chunk Sometimes/RB it/PRP can/MD)\n",
            "(Chunk history/NN)\n",
            "(Chunk wide/JJ arc/NN ,/,)\n",
            "(Chunk unknown/JJ shore/NN ./.)\n",
            "(Chunk Yet/CC)\n",
            "(Chunk destination/NN)\n",
            "(Chunk history/NN)\n",
            "(Chunk human/JJ action/NN ,/, and/CC)\n",
            "(Chunk great/JJ movement/NN)\n",
            "(Chunk history/NN)\n",
            "(Chunk point/NN)\n",
            "(Chunk choosing/NN ./.)\n",
            "(Chunk Lincoln/NNP could/MD)\n",
            "(Chunk peace/NN)\n",
            "(Chunk cost/NN)\n",
            "(Chunk disunity/NN and/CC continued/JJ slavery/NN ./.)\n",
            "(Chunk Martin/NNP Luther/NNP King/NNP could/MD)\n",
            "(Chunk Birmingham/NNP or/CC)\n",
            "(Chunk Selma/NNP ,/, and/CC)\n",
            "(Chunk only/RB half/PDT)\n",
            "(Chunk victory/NN)\n",
            "(Chunk segregation/NN ./.)\n",
            "(Chunk United/NNP States/NNPS could/MD)\n",
            "(Chunk permanent/JJ division/NN)\n",
            "(Chunk Europe/NNP ,/, and/CC)\n",
            "(Chunk complicit/NNS)\n",
            "(Chunk oppression/NN)\n",
            "(Chunk others/NNS ./.)\n",
            "(Chunk Today/NN ,/,)\n",
            "(Chunk far/RB)\n",
            "(Chunk our/PRP$ own/JJ historical/JJ journey/NN ,/, we/PRP must/MD)\n",
            "(Chunk :/: Will/MD we/PRP)\n",
            "(Chunk back/RP ,/, or/CC)\n",
            "(Chunk well/RB ?/.)\n",
            "(Chunk history/NN)\n",
            "(Chunk down/RP)\n",
            "(Chunk books/NNS ,/, it/PRP)\n",
            "(Chunk courage/NN ./.)\n",
            "(Chunk Americans/NNPS)\n",
            "(Chunk us/PRP ,/, we/PRP will/MD)\n",
            "(Chunk courage/NN and/CC we/PRP will/MD)\n",
            "(Chunk well/RB ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk freedom/NN 's/POS advance/NN ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk and/CC)\n",
            "(Chunk global/JJ economy/NN ./.)\n",
            "(Chunk We/PRP will/MD)\n",
            "(Chunk moral/JJ commitments/NNS)\n",
            "(Chunk land/NN ./.)\n",
            "(Chunk And/CC so/RB we/PRP)\n",
            "(Chunk forward/RB --/: optimistic/JJ)\n",
            "(Chunk our/PRP$ country/NN ,/, faithful/JJ)\n",
            "(Chunk its/PRP$ cause/NN ,/, and/CC confident/NN)\n",
            "(Chunk victories/NNS)\n",
            "(Chunk ./.)\n",
            "(Chunk May/NNP God/NNP bless/NN America/NNP ./.)\n",
            "(Chunk (/( Applause/NNP ./. )/))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a small diffeence between Chunking and chinking by using NLTK or using RegEx\n",
        "\n",
        "Chunks are made up of words and the kinds of words are defined using the part-of-speech tags.\n",
        "\n",
        "whereas, One can even define a pattern or words that can’t be a part of chuck and such words are known as chinks"
      ],
      "metadata": {
        "id": "rKUrwAqr7gcg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition with NLTK**\n",
        "\n",
        "One of the most common forms of chunking in natural language processing is called \"Named Entity Recognition.\" NLTK is able to identify people, places, things, locations, monetary figures, and more.\n",
        "\n",
        "There are two major options with NLTK's named entity recognition: either recognize all named entities, or recognize named entities as their respective type, like people, places, locations, etc.\n",
        "\n",
        "Here, with the option of binary = True, this means either something is a named entity, or not. There will be no further detail.\n",
        "\n"
      ],
      "metadata": {
        "id": "jAI89ZBr7_Xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWGSz7uW8W0u",
        "outputId": "c03e1589-617d-4591-a4bc-d8f529dd1640"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JweweF38k5N",
        "outputId": "0daca2e3-9803-48b3-f4c7-e58156802feb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_content():\n",
        "    try:\n",
        "        for i in tokenized[5:]:\n",
        "            words = nltk.word_tokenize(i)\n",
        "            tagged = nltk.pos_tag(words)\n",
        "            namedEnt = nltk.ne_chunk(tagged, binary=True)\n",
        "            # namedEnt.draw()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "\n",
        "process_content()"
      ],
      "metadata": {
        "id": "2BT_IZvM7YMT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Classification**\n",
        "\n",
        "**Text classification using NLTK**\n",
        "\n",
        "Text classification using NLTK (Natural Language Toolkit) is a common task in natural language processing (NLP). NLTK provides various tools and algorithms to preprocess text data, extract features, and train classification models.\n",
        "\n"
      ],
      "metadata": {
        "id": "el35epqA8vRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLS4fL7gPt3r",
        "outputId": "a817be8d-2134-460b-a1aa-18e65c286bd0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "\n",
        "# shuffle the documents\n",
        "random.shuffle(documents)\n",
        "\n",
        "print('Number of Documents: {}'.format(len(documents)))\n",
        "print('First Review: {}'.format(documents[1]))\n",
        "\n",
        "all_words = []\n",
        "for w in movie_reviews.words():\n",
        "    all_words.append(w.lower())\n",
        "\n",
        "all_words = nltk.FreqDist(all_words)\n",
        "\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))\n",
        "print('The word happy: {}'.format(all_words[\"happy\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEDFwtNK8ptY",
        "outputId": "4261c0b6-f14b-41cf-8993-ee151cc8f1a8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Documents: 2000\n",
            "First Review: (['mr', '.', 'bean', ',', 'a', 'bumbling', 'security', 'guard', 'from', 'england', 'is', 'sent', 'to', 'la', 'to', 'help', 'with', 'the', 'grandiose', 'homecoming', 'of', 'a', 'masterpiece', 'american', 'painting', '.', 'the', 'first', 'two', 'words', 'should', 'have', 'said', 'enough', 'to', 'let', 'you', 'know', 'what', 'occurs', 'during', 'bean', \"'\", 's', 'trip', 'to', 'la', ',', 'but', 'if', 'they', 'didn', \"'\", 't', 'look', 'out', 'because', 'you', 'are', 'in', 'for', 'a', 'rather', 'interesting', 'if', 'not', 'odd', 'ride', '.', 'heck', 'depending', 'on', 'your', 'humor', 'you', 'might', 'end', 'up', 'laughing', 'through', 'the', 'whole', 'flick', '.', 'either', 'way', 'look', 'out', 'america', 'bean', 'is', 'coming', '.', 'well', ',', 'what', 'can', 'really', 'be', 'said', 'about', 'this', 'movie', ',', 'there', 'is', 'very', 'little', 'discernible', 'plot', '.', 'that', 'much', 'is', 'not', 'hard', 'to', 'grapple', 'with', 'for', 'it', 'is', 'a', 'slapstick', 'comedy', '.', 'it', 'achieves', 'that', 'goal', 'rather', 'admirably', ',', 'but', 'because', 'it', 'is', 'that', ',', 'the', 'plot', 'is', 'just', 'screaming', 'for', 'help', '.', 'the', 'whole', 'premise', 'that', 'the', 'movie', 'is', 'based', 'on', 'is', 'to', 'say', 'the', 'least', 'flawed', '.', 'the', 'movie', 'had', 'its', 'funny', 'moments', 'but', 'there', 'was', 'no', 'real', 'story', 'line', 'other', 'than', 'something', 'that', 'could', 'be', 'thought', 'up', 'on', 'a', 'whim', 'and', 'carried', 'through', 'and', 'in', 'many', 'causes', 'ad', '-', 'libbed', 'as', 'you', 'went', '.', 'don', \"'\", 't', 'go', 'into', 'this', 'movie', 'expecting', 'and', 'theatrical', 'masterpiece', '.', 'but', 'if', 'this', 'form', 'of', 'humor', 'floats', 'your', 'boat', 'then', 'you', 'will', 'truly', 'enjoy', 'this', 'movie', ',', 'even', 'if', 'you', 'don', \"'\", 't', 'like', 'slapstick', 'style', 'humor', 'you', 'will', 'end', 'up', 'laughing', 'because', 'something', \"'\", 's', 'are', 'just', 'so', 'stupid', '.', 'the', 'movie', 'goes', 'out', 'and', 'accomplishes', 'what', 'it', 'aims', ',', 'or', 'so', 'it', 'seems', '.', 'now', 'when', 'you', 'look', 'at', 'the', 'acting', 'in', 'this', 'movie', 'you', 'have', 'to', 'think', 'about', 'two', 'things', ',', 'first', 'was', 'there', 'any', 'real', 'acting', 'and', 'how', 'hard', 'is', 'it', 'to', 'act', 'in', 'the', 'slapstick', 'manner', '.', 'well', ',', 'there', 'was', 'no', 'real', 'acting', 'in', 'this', 'movie', 'but', 'some', 'of', 'the', 'slapstick', 'wasn', \"'\", 't', 'the', 'easiest', 'i', 'am', 'sure', '.', 'i', 'have', 'to', 'concede', 'that', 'mr', '.', 'atkinson', \"'\", 's', 'acting', 'in', 'this', 'movie', 'is', 'well', 'done', '.', 'although', 'the', 'role', 'isn', \"'\", 't', 'too', 'demanding', 'the', 'slapstick', 'is', '.', 'i', 'think', 'that', 'the', 'character', 'could', 'have', 'had', 'a', 'bit', 'more', 'dialogue', ',', 'it', 'would', 'have', 'added', 'quite', 'a', 'bit', 'to', 'the', 'overall', 'effect', 'of', 'the', 'movie', '.', 'now', 'the', 'rest', 'of', 'the', 'actors', 'in', 'the', 'movie', ',', 'bad', 'acting', 'and', 'poor', 'casting', '.', 'i', 'think', 'that', 'the', 'role', 'opposite', 'bean', 'could', 'have', 'been', 'better', ',', 'just', 'seemed', 'wrong', 'for', 'the', 'movie', '.', 'a', 'different', 'actor', 'might', 'have', 'done', 'a', 'better', 'job', 'of', 'it', 'but', 'i', 'wont', 'presume', 'that', 'wasn', \"'\", 't', 'what', 'was', 'trying', 'to', 'be', 'achieved', '.', 'one', 'thing', 'that', 'i', 'must', 'say', ',', 'simply', 'to', 'get', 'if', 'off', 'my', 'chest', 'is', 'that', 'i', 'think', 'transferring', 'a', 'sitcom', 'to', 'tv', 'usually', 'produces', 'rather', 'disastrous', 'results', '.', 'tv', 'shows', 'should', 'do', 'just', 'that', 'stay', 'on', 'tv', ',', 'it', 'will', 'probably', 'save', 'some', 'producers', 'from', 'getting', 'ulcers', '.', 'i', 'can', 'only', 'think', 'of', 'a', 'couple', 'examples', 'of', 'tv', 'going', 'to', 'the', 'big', 'screen', 'effectively', ',', 'the', 'best', 'known', 'of', 'those', 'would', 'have', 'to', 'be', 'star', 'trek', '.', 'bean', 'seriously', 'fails', 'to', 'accomplish', 'anything', 'close', 'to', 'what', 'that', 'series', 'gone', 'movie', 'achieved', '.', 'now', 'another', 'thing', 'that', 'i', 'have', 'to', 'state', 'again', 'is', 'this', 'movie', 'has', 'narrowed', 'its', 'target', 'audience', 'fairly', 'tightly', '.', 'the', 'form', 'of', 'humor', 'in', 'this', 'movie', 'will', 'not', 'be', 'liked', 'by', 'most', 'people', ',', 'these', 'people', 'will', 'think', 'like', 'i', 'did', 'that', 'this', 'movie', 'is', 'stupid', 'and', 'pointless', '.', 'but', 'if', 'you', 'like', 'the', 'tv', 'show', 'you', 'might', 'actually', 'like', 'this', 'movie', '.', 'but', 'to', 'be', 'on', 'the', 'safe', 'side', 'i', 'am', 'opting', 'to', 'recommend', 'you', 'save', 'your', 'money', 'and', 'not', 'go', 'to', 'see', 'this', 'movie', '.', 'there', 'are', 'many', 'movies', 'that', 'are', 'truly', 'worth', 'seeing', 'unlike', 'this', 'one', '.'], 'neg')\n",
            "Most common words: [(',', 77717), ('the', 76529), ('.', 65876), ('a', 38106), ('and', 35576), ('of', 34123), ('to', 31937), (\"'\", 30585), ('is', 25195), ('in', 21822), ('s', 18513), ('\"', 17612), ('it', 16107), ('that', 15924), ('-', 15595)]\n",
            "The word happy: 215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(all_words))\n",
        "word_features = list(all_words.keys())[:4000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v-PuvOgQESB",
        "outputId": "2f9ff1ef-d3f5-44e4-be82-e8ada74853a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_features(document):\n",
        "    words = set(document)\n",
        "    features = {}\n",
        "    for w in word_features:\n",
        "        features[w] = (w in words)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "# Lets use an example from a negative review\n",
        "features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
        "for key, value in features.items():\n",
        "    if value == True:\n",
        "        print (key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSW5bdmNUn4q",
        "outputId": "4565b0a1-7d03-4fb8-e611-be7bcf93069d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plot\n",
            ":\n",
            "two\n",
            "teen\n",
            "couples\n",
            "go\n",
            "to\n",
            "a\n",
            "church\n",
            "party\n",
            ",\n",
            "drink\n",
            "and\n",
            "then\n",
            "drive\n",
            ".\n",
            "they\n",
            "get\n",
            "into\n",
            "an\n",
            "accident\n",
            "one\n",
            "of\n",
            "the\n",
            "guys\n",
            "dies\n",
            "but\n",
            "his\n",
            "girlfriend\n",
            "continues\n",
            "see\n",
            "him\n",
            "in\n",
            "her\n",
            "life\n",
            "has\n",
            "nightmares\n",
            "what\n",
            "'\n",
            "s\n",
            "deal\n",
            "?\n",
            "watch\n",
            "movie\n",
            "\"\n",
            "sorta\n",
            "find\n",
            "out\n",
            "critique\n",
            "mind\n",
            "-\n",
            "fuck\n",
            "for\n",
            "generation\n",
            "that\n",
            "touches\n",
            "on\n",
            "very\n",
            "cool\n",
            "idea\n",
            "presents\n",
            "it\n",
            "bad\n",
            "package\n",
            "which\n",
            "is\n",
            "makes\n",
            "this\n",
            "review\n",
            "even\n",
            "harder\n",
            "write\n",
            "since\n",
            "i\n",
            "generally\n",
            "applaud\n",
            "films\n",
            "attempt\n",
            "break\n",
            "mold\n",
            "mess\n",
            "with\n",
            "your\n",
            "head\n",
            "such\n",
            "(\n",
            "lost\n",
            "highway\n",
            "&\n",
            "memento\n",
            ")\n",
            "there\n",
            "are\n",
            "good\n",
            "ways\n",
            "making\n",
            "all\n",
            "types\n",
            "these\n",
            "folks\n",
            "just\n",
            "didn\n",
            "t\n",
            "snag\n",
            "correctly\n",
            "seem\n",
            "have\n",
            "taken\n",
            "pretty\n",
            "neat\n",
            "concept\n",
            "executed\n",
            "terribly\n",
            "so\n",
            "problems\n",
            "well\n",
            "its\n",
            "main\n",
            "problem\n",
            "simply\n",
            "too\n",
            "jumbled\n",
            "starts\n",
            "off\n",
            "normal\n",
            "downshifts\n",
            "fantasy\n",
            "world\n",
            "you\n",
            "as\n",
            "audience\n",
            "member\n",
            "no\n",
            "going\n",
            "dreams\n",
            "characters\n",
            "coming\n",
            "back\n",
            "from\n",
            "dead\n",
            "others\n",
            "who\n",
            "look\n",
            "like\n",
            "strange\n",
            "apparitions\n",
            "disappearances\n",
            "looooot\n",
            "chase\n",
            "scenes\n",
            "tons\n",
            "weird\n",
            "things\n",
            "happen\n",
            "most\n",
            "not\n",
            "explained\n",
            "now\n",
            "personally\n",
            "don\n",
            "trying\n",
            "unravel\n",
            "film\n",
            "every\n",
            "when\n",
            "does\n",
            "give\n",
            "me\n",
            "same\n",
            "clue\n",
            "over\n",
            "again\n",
            "kind\n",
            "fed\n",
            "up\n",
            "after\n",
            "while\n",
            "biggest\n",
            "obviously\n",
            "got\n",
            "big\n",
            "secret\n",
            "hide\n",
            "seems\n",
            "want\n",
            "completely\n",
            "until\n",
            "final\n",
            "five\n",
            "minutes\n",
            "do\n",
            "make\n",
            "entertaining\n",
            "thrilling\n",
            "or\n",
            "engaging\n",
            "meantime\n",
            "really\n",
            "sad\n",
            "part\n",
            "arrow\n",
            "both\n",
            "dig\n",
            "flicks\n",
            "we\n",
            "actually\n",
            "figured\n",
            "by\n",
            "half\n",
            "way\n",
            "point\n",
            "strangeness\n",
            "did\n",
            "start\n",
            "little\n",
            "bit\n",
            "sense\n",
            "still\n",
            "more\n",
            "guess\n",
            "bottom\n",
            "line\n",
            "movies\n",
            "should\n",
            "always\n",
            "sure\n",
            "before\n",
            "given\n",
            "password\n",
            "enter\n",
            "understanding\n",
            "mean\n",
            "showing\n",
            "melissa\n",
            "sagemiller\n",
            "running\n",
            "away\n",
            "visions\n",
            "about\n",
            "20\n",
            "throughout\n",
            "plain\n",
            "lazy\n",
            "!\n",
            "okay\n",
            "people\n",
            "chasing\n",
            "know\n",
            "need\n",
            "how\n",
            "giving\n",
            "us\n",
            "different\n",
            "offering\n",
            "further\n",
            "insight\n",
            "down\n",
            "apparently\n",
            "studio\n",
            "took\n",
            "director\n",
            "chopped\n",
            "themselves\n",
            "shows\n",
            "might\n",
            "ve\n",
            "been\n",
            "decent\n",
            "here\n",
            "somewhere\n",
            "suits\n",
            "decided\n",
            "turning\n",
            "music\n",
            "video\n",
            "edge\n",
            "would\n",
            "actors\n",
            "although\n",
            "wes\n",
            "bentley\n",
            "seemed\n",
            "be\n",
            "playing\n",
            "exact\n",
            "character\n",
            "he\n",
            "american\n",
            "beauty\n",
            "only\n",
            "new\n",
            "neighborhood\n",
            "my\n",
            "kudos\n",
            "holds\n",
            "own\n",
            "entire\n",
            "feeling\n",
            "unraveling\n",
            "overall\n",
            "doesn\n",
            "stick\n",
            "because\n",
            "entertain\n",
            "confusing\n",
            "rarely\n",
            "excites\n",
            "feels\n",
            "redundant\n",
            "runtime\n",
            "despite\n",
            "ending\n",
            "explanation\n",
            "craziness\n",
            "came\n",
            "oh\n",
            "horror\n",
            "slasher\n",
            "flick\n",
            "packaged\n",
            "someone\n",
            "assuming\n",
            "genre\n",
            "hot\n",
            "kids\n",
            "also\n",
            "wrapped\n",
            "production\n",
            "years\n",
            "ago\n",
            "sitting\n",
            "shelves\n",
            "ever\n",
            "whatever\n",
            "skip\n",
            "where\n",
            "joblo\n",
            "nightmare\n",
            "elm\n",
            "street\n",
            "3\n",
            "7\n",
            "/\n",
            "10\n",
            "blair\n",
            "witch\n",
            "2\n",
            "crow\n",
            "9\n",
            "salvation\n",
            "4\n",
            "stir\n",
            "echoes\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
      ],
      "metadata": {
        "id": "vJEfOT2VUs8f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "\n",
        "# define a seed for reproducibility\n",
        "seed = 1\n",
        "\n",
        "# split the data into training and testing datasets\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)\n"
      ],
      "metadata": {
        "id": "4XPs9w1vUxUi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3L0EFVQU0MP",
        "outputId": "b441a684-a8f9-4a93-a8ae-ce0f667176b5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500\n",
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
        "\n",
        "# train the model on the training data\n",
        "model.train(training)\n",
        "\n",
        "# and test on the testing dataset!\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPlV7PjhU7bA",
        "outputId": "648ce1c3-5abf-45a8-9c6b-a6eb428c2bb9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Accuracy: 81.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}